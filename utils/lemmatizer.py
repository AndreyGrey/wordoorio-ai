#!/usr/bin/env python3
"""
–õ–µ–º–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –∏ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–æ–≤

- –ê–Ω–≥–ª–∏–π—Å–∫–∏–π: spaCy (en_core_web_sm)
- –†—É—Å—Å–∫–∏–π: pymorphy2
"""

import spacy

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ
_nlp = None
_morph = None


def _get_nlp():
    """–õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–π –º–æ–¥–µ–ª–∏"""
    global _nlp
    if _nlp is None:
        print("üìö –ó–∞–≥—Ä—É–∂–∞–µ–º spaCy –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ...", flush=True)
        _nlp = spacy.load("en_core_web_sm", disable=["parser", "ner"])
        print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞", flush=True)
    return _nlp


def lemmatize(text: str) -> str:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å–ª–æ–≤–æ –∏–ª–∏ —Ñ—Ä–∞–∑—É –≤ —Å–ª–æ–≤–∞—Ä–Ω—É—é —Ñ–æ—Ä–º—É

    –ü—Ä–∏–º–µ—Ä—ã:
        - "incentives" ‚Üí "incentive"
        - "running" ‚Üí "run"
        - "went" ‚Üí "go"
        - "gave up" ‚Üí "give up"
        - "making sense" ‚Üí "make sense"

    Args:
        text: –°–ª–æ–≤–æ –∏–ª–∏ —Ñ—Ä–∞–∑–∞ –¥–ª—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏

    Returns:
        –õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    if not text or not text.strip():
        return text

    nlp = _get_nlp()
    doc = nlp(text.strip())

    # –õ–µ–º–º–∞—Ç–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ
    lemmas = [token.lemma_ for token in doc]

    return " ".join(lemmas)


def _get_morph():
    """–õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ pymorphy2 –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞"""
    global _morph
    if _morph is None:
        import pymorphy2
        print("üìö –ó–∞–≥—Ä—É–∂–∞–µ–º pymorphy2 –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ...", flush=True)
        _morph = pymorphy2.MorphAnalyzer()
        print("‚úÖ pymorphy2 –∑–∞–≥—Ä—É–∂–µ–Ω", flush=True)
    return _morph


def lemmatize_russian(text: str) -> str:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç –≤ —Å–ª–æ–≤–∞—Ä–Ω—É—é —Ñ–æ—Ä–º—É.

    –î–ª—è –æ–¥–∏–Ω–æ—á–Ω—ã—Ö —Å–ª–æ–≤:
    - –ü—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–µ/–ø—Ä–∏—á–∞—Å—Ç–∏—è ‚Üí –º.—Ä. –µ–¥.—á. –∏–º.–ø.
    - –ì–ª–∞–≥–æ–ª—ã ‚Üí –∏–Ω—Ñ–∏–Ω–∏—Ç–∏–≤
    - –°—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ ‚Üí –µ–¥.—á. –∏–º.–ø.

    –î–ª—è —Ñ—Ä–∞–∑:
    - –õ–µ–º–º–∞—Ç–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ (–æ—Å–Ω–æ–≤–Ω–æ–π –≥–ª–∞–≥–æ–ª/–ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω–æ–µ)
    - –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å

    –ü—Ä–∏–º–µ—Ä—ã:
    - "–∑–∞—Ö–≤–∞—Ç—ã–≤–∞—é—â–∏–µ" ‚Üí "–∑–∞—Ö–≤–∞—Ç—ã–≤–∞—é—â–∏–π"
    - "–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–ª–∏—Å—å" ‚Üí "–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è"
    - "–∑–∞—Å—ã–ø–∞–ª–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏" ‚Üí "–∑–∞—Å—ã–ø–∞—Ç—å –≤–æ–ø—Ä–æ—Å–∞–º–∏"

    Args:
        text: –°–ª–æ–≤–æ –∏–ª–∏ —Ñ—Ä–∞–∑–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º

    Returns:
        –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    if not text or not text.strip():
        return text

    morph = _get_morph()
    words = text.strip().split()

    if len(words) == 1:
        # –û–¥–∏–Ω–æ—á–Ω–æ–µ —Å–ª–æ–≤–æ ‚Äî –ø–æ–ª–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        parsed = morph.parse(words[0])[0]
        return parsed.normal_form
    else:
        # –§—Ä–∞–∑–∞ ‚Äî –ª–µ–º–º–∞—Ç–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ
        parsed = morph.parse(words[0])[0]
        words[0] = parsed.normal_form
        return ' '.join(words)


# –¢–µ—Å—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
if __name__ == "__main__":
    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ª–µ–º–º–∞—Ç–∏–∑–∞—Ç–æ—Ä...\n")

    print("=== –ê–Ω–≥–ª–∏–π—Å–∫–∏–π (spaCy) ===")
    english_tests = [
        "incentives",
        "running",
        "went",
        "bigger",
        "stories",
        "gave up",
        "making sense",
        "came across",
        "compelling arguments",
        "amplifying",
    ]

    for test in english_tests:
        result = lemmatize(test)
        print(f"  '{test}' ‚Üí '{result}'")

    print("\n=== –†—É—Å—Å–∫–∏–π (pymorphy2) ===")
    russian_tests = [
        "–∑–∞—Ö–≤–∞—Ç—ã–≤–∞—é—â–∏–µ",
        "–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–ª–∏—Å—å",
        "–ø–æ–¥–¥–µ–ª—å–Ω—ã–µ",
        "–ø–æ–¥–¥–µ–ª—å–Ω–∞—è",
        "—Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á—ë–Ω–Ω–æ–µ",
        "–Ω–∞—Ä—É—à–∞—é—â–∞—è",
        "–∫–∞—Å–∞–µ—Ç—Å—è",
        "–ø–æ—è–≤–∏–ª—Å—è",
        "–∑–∞—Å—ã–ø–∞–ª–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏",
        "–≤—Ç—è–Ω—É—Ç –≤ –∫–æ–Ω—Ñ–ª–∏–∫—Ç",
    ]

    for test in russian_tests:
        result = lemmatize_russian(test)
        print(f"  '{test}' ‚Üí '{result}'")

    print("\n‚úÖ –¢–µ—Å—Ç—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã")
