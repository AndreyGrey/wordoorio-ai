#!/usr/bin/env python3
"""
üìã –ö–û–ù–¢–†–ê–ö–¢–´ –°–ò–°–¢–ï–ú–´ WORDOORIO

–ï–¥–∏–Ω—ã–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã –¥–ª—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã.
–ò–∑–º–µ–Ω–µ–Ω–∏–µ —ç—Ç–∏—Ö –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤ –≤–ª–∏—è–µ—Ç –Ω–∞ –≤—Å—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É!
"""

from dataclasses import dataclass, field
from typing import List, Dict, Optional, Any
from abc import ABC, abstractmethod


@dataclass
class Highlight:
    """–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ö–∞–π–ª–∞–π—Ç –≤–æ –≤—Å–µ–π —Å–∏—Å—Ç–µ–º–µ"""
    highlight: str                    # –ù–∞–π–¥–µ–Ω–Ω–æ–µ —Å–ª–æ–≤–æ/—Ñ—Ä–∞–∑–∞
    context: str                     # –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞
    highlight_translation: str       # –ü–µ—Ä–µ–≤–æ–¥ —Å–ª–æ–≤–∞/—Ñ—Ä–∞–∑—ã (–∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π)
    cefr_level: str = "C1"          # –£—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
    importance_score: int = 85       # –í–∞–∂–Ω–æ—Å—Ç—å 0-100
    dictionary_meanings: List[str] = field(default_factory=list)

    def to_dict(self) -> Dict[str, Any]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è JSON"""
        return {
            'highlight': self.highlight,
            'context': self.context,
            'highlight_translation': self.highlight_translation,
            'dictionary_meanings': self.dictionary_meanings,
            'cefr_level': self.cefr_level,
            'importance_score': self.importance_score
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'Highlight':
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏–∑ —Å–ª–æ–≤–∞—Ä—è"""
        return cls(
            highlight=data['highlight'],
            context=data['context'],
            highlight_translation=data.get('highlight_translation', ''),
            cefr_level=data.get('cefr_level', 'C1'),
            importance_score=data.get('importance_score', 85),
            dictionary_meanings=data.get('dictionary_meanings', [])
        )


@dataclass
class AgentResponse:
    """–û—Ç–≤–µ—Ç –æ—Ç –∞–≥–µ–Ω—Ç–∞ –≤ Yandex AI Studio"""
    highlight: str                   # –ê–Ω–≥–ª–∏–π—Å–∫–æ–µ —Å–ª–æ–≤–æ/—Ñ—Ä–∞–∑–∞
    category: str                    # "word" | "expression"
    translation: str                 # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ (—Ä—É—Å—Å–∫–∏–π)
    examples: List[str]              # –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    collocations: List[str]          # –£—Å—Ç–æ–π—á–∏–≤—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'AgentResponse':
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏–∑ —Å–ª–æ–≤–∞—Ä—è (–ø–∞—Ä—Å–∏–Ω–≥ JSON –æ—Ç AI Studio)"""
        return cls(
            highlight=data.get('highlight', ''),
            category=data.get('category', 'word'),
            translation=data.get('translation', ''),
            examples=data.get('examples', []),
            collocations=data.get('collocations', [])
        )


@dataclass
class AnalysisRequest:
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    text: str                        # –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    page_id: str = "main"           # ID —Å—Ç—Ä–∞–Ω–∏—Ü—ã: "main", "experimental", "future"
    user_session: Optional[str] = None
    
    def validate(self) -> Optional[str]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—à–∏–±–∫—É –∏–ª–∏ None"""
        if not self.text.strip():
            return "–¢–µ–∫—Å—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º"
        if len(self.text.split()) < 5:
            return "–¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π (–º–∏–Ω–∏–º—É–º 5 —Å–ª–æ–≤)"
        if len(self.text) > 100000:
            return "–¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π (–º–∞–∫—Å–∏–º—É–º 100000 —Å–∏–º–≤–æ–ª–æ–≤)"
        return None


@dataclass
class AnalysisResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞"""
    success: bool
    highlights: List[Highlight] = field(default_factory=list)
    stats: Dict[str, int] = field(default_factory=dict)
    error: Optional[str] = None
    performance: Optional[Dict[str, Any]] = None  # –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    
    def get_stats(self) -> Dict[str, int]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∞–Ω–∞–ª–∏–∑–∞"""
        return {
            'total_highlights': len(self.highlights),
            'total_words': self.stats.get('total_words', 0),
            'success': 1 if self.success else 0
        }
    
    def to_json_dict(self) -> Dict[str, Any]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ JSON –¥–ª—è API –æ—Ç–≤–µ—Ç–∞"""
        return {
            'success': self.success,
            'highlights': [h.to_dict() for h in self.highlights],
            'stats': self.get_stats(),
            'error': self.error,
            'performance': self.performance
        }


# ============================================================================
# –ê–ë–°–¢–†–ê–ö–¢–ù–´–ï –ò–ù–¢–ï–†–§–ï–ô–°–´ (–∫–æ–Ω—Ç—Ä–∞–∫—Ç—ã –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏)
# ============================================================================

class AIClient(ABC):
    """–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è AI –∫–ª–∏–µ–Ω—Ç–æ–≤ (Yandex GPT, OpenAI, etc.)"""
    
    @abstractmethod
    async def request_gpt(self, prompt: str) -> str:
        """–û—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∫ AI –∏ –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç"""
        pass
    
    @abstractmethod
    async def translate_text(self, text: str, target_lang: str = "ru") -> str:
        """–ü–µ—Ä–µ–≤–µ—Å—Ç–∏ —Ç–µ–∫—Å—Ç"""
        pass


class AnalysisRepository(ABC):
    """–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
    
    @abstractmethod
    def save_analysis(self, request: AnalysisRequest, result: AnalysisResult) -> int:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç ID"""
        pass
    
    @abstractmethod
    def get_analysis_by_id(self, analysis_id: int) -> Optional[AnalysisResult]:
        """–ü–æ–ª—É—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –ø–æ ID"""
        pass
    
    @abstractmethod
    def search_by_word(self, word: str) -> List[Dict]:
        """–ù–∞–π—Ç–∏ –∞–Ω–∞–ª–∏–∑—ã —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ —Å–ª–æ–≤–æ"""
        pass


class DeduplicationService(ABC):
    """–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
    
    @abstractmethod
    def remove_duplicates(self, highlights: List[Highlight]) -> List[Highlight]:
        """–£–±—Ä–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –∏–∑ —Å–ø–∏—Å–∫–∞ —Ö–∞–π–ª–∞–π—Ç–æ–≤"""
        pass


# ============================================================================
# –£–¢–ò–õ–ò–¢–´
# ============================================================================

def create_error_result(error_message: str) -> AnalysisResult:
    """–°–æ–∑–¥–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –æ—à–∏–±–∫–æ–π"""
    return AnalysisResult(
        success=False,
        error=error_message,
        stats={'total_words': 0, 'total_highlights': 0}
    )


def create_success_result(highlights: List[Highlight], 
                         total_words: int,
                         performance: Optional[Dict] = None) -> AnalysisResult:
    """–°–æ–∑–¥–∞—Ç—å —É—Å–ø–µ—à–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç"""
    return AnalysisResult(
        success=True,
        highlights=highlights,
        stats={'total_words': total_words, 'total_highlights': len(highlights)},
        performance=performance
    )