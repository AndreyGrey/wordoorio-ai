# Лемматизация: проблемы, анализ, план

Рабочий документ по улучшению лемматизации в Wordoorio.

---

## Текущий пайплайн

```
User Text → AI Agents (Qwen3-235B, параллельно)
           ↓
    ┌──────────┬──────────┐
    │ Agent #1 │ Agent #2 │
    │  Words   │ Phrases  │
    └──────────┴──────────┘
           ↓
    _dict_to_highlight() для каждого результата:
      1. word = highlight из AI (сырой вывод)
      2. word_lemma = lemmatize(word) через spaCy en_core_web_sm
      3. Для фраз (2+ слов): словарь пропускается, final_lemma = word_lemma
      4. Для слов (1 слово):
         - Если Yandex Dictionary знает оригинал → final_lemma = word.lower()
         - Если нет → пробуем спросить word_lemma → final_lemma = word_lemma
      5. highlight = word (СЫРОЙ вывод AI — показывается на карточке)
      6. lemma = final_lemma (используется ТОЛЬКО для дедупликации)
      7. highlight_translation = из AI (без нормализации)
           ↓
    Remove Duplicates (по lemma)
           ↓
    Highlights → Frontend
```

**Ключевые файлы:**
- `core/analysis_orchestrator.py` — основная логика (метод `_dict_to_highlight`, строки 206-304)
- `utils/lemmatizer.py` — spaCy лемматизация (только английский)
- `contracts/analysis_contracts.py` — типы данных (Highlight, AgentResponse)

---

## Собранные примеры проблем (13 шт.)

### Category A — Русский перевод не в словарной форме (11 примеров)

AI-агент возвращает перевод, согласованный с контекстом (род, число, время), а не в словарной форме. Русская лемматизация (pymorphy2) была удалена в коммите e9d0f10.

| # | EN (highlight) | RU (translation) | Должно быть | Проблема |
|---|---|---|---|---|
| 1 | intriguing | захватывающие | захватывающий | мн.ч. → м.р. ед.ч. |
| 2 | adapted | адаптировались | адаптироваться | прош.вр. мн.ч. → инфинитив |
| 3 | bogus | поддельные | поддельный | мн.ч. → м.р. ед.ч. |
| 4 | counterfeit | поддельная | поддельный | ж.р. → м.р. |
| 5 | concentrated | сосредоточённое | сосредоточённый | ср.р. → м.р. |
| 6 | disruptive | нарушающая | нарушающий | ж.р. → м.р. |
| 7 | underlying | лежащие в основе | лежащий в основе | мн.ч. → м.р. ед.ч. |
| 8 | pertains | касается | касаться | 3 лицо → инфинитив |
| 9 | popped up | появился | появиться | прош.вр. → инфинитив |
| 10 | peppered with | засыпали (вопросами) | засыпать (вопросами) | прош.вр. → инфинитив |
| 11 | embroiled in | втянут в (конфликт) | втянуть в (конфликт) | кр. прич. → инфинитив |

**Корень:** pymorphy2 удалён, AI-агент не всегда возвращает словарную форму.

### Category B — Английское слово не в базовой форме (7 примеров)

Карточка показывает сырой вывод AI (`highlight=word`), а не spaCy-лемму (`word_lemma`). spaCy уже вычисляет лемму, но она не используется для отображения.

| # | Показывается | Должно быть | Источник |
|---|---|---|---|
| 1 | pertains | pertain | Agent #1 (нарушил промпт) |
| 2 | assessing | assess | Agent #1 |
| 3 | caught on to | catch on to | Agent #2 (промпт v1 просил "как в тексте") |
| 4 | counting on | count on | Agent #2 |
| 5 | popped up | pop up | Agent #2 |
| 6 | peppered with | pepper with | Agent #2 |
| 7 | embroiled in | embroil in | Agent #2 |

**Корень в коде:** `analysis_orchestrator.py:293` — `highlight=word` вместо `highlight=word_lemma`.
**Корень в промпте Agent #2 v1:** "Точно как встречается в тексте" — просил контекстную форму.

### Category C — Несоответствие части речи (2 примера)

| # | Слово | Проблема |
|---|---|---|
| 1 | skirting | Переведено как глагол "обходить", но в тексте используется как существительное |
| 2 | assessing | Переведено как причастие "оценивающий", в тексте используется как глагол |

**Корень:** AI-агент не возвращает POS, spaCy без контекста не может определить часть речи однозначно.

---

## Анализ промптов агентов

### Agent #1 (Words) — промпт v1

**highlight:** Промпт УЖЕ просит базовую форму. Правила хорошие:
- Существительные → ед.ч.
- Глаголы → инфинитив
- Причастия/герундии → как есть (amplifying, compelling)

**highlight_translation:** Промпт говорил "Перевод должен соответствовать грамматической форме highlight" — это НЕ словарная форма. Если highlight = "intriguing" (причастие, оставлено как есть), то перевод = причастие. Но русский род/число не уточнялся → AI возвращал "захватывающие" (мн.ч.) вместо "захватывающий" (м.р. ед.ч.).

**Вывод:** AI иногда нарушает собственные правила (pertains вместо pertain), но главная проблема — отсутствие инструкций по русской словарной форме.

### Agent #2 (Phrases) — промпт v1

**highlight:** Промпт просил "Точно как встречается в тексте" → "popped up", "caught on to" — это BY DESIGN.

**highlight_translation:** Нет указаний на словарную форму → "появился", "засыпали" — контекстные формы.

**Вывод:** Промпт Agent #2 нужно менять — и highlight (базовая форма), и translation (словарная форма).

---

## Решение: двухуровневая защита

### Уровень 1: Промпты агентов (v2.0)

**Статус:** Готово, промпты подготовлены, нужно применить в AI Studio.

Файл: `docs/PROMPTS.md` — v2.0 для обоих агентов.

**Agent #1 — изменения:**
- `highlight_translation`: "одно слово на русском В СЛОВАРНОЙ ФОРМЕ"
  - Прилагательные/причастия → м.р. ед.ч. им.п.
  - Глаголы → инфинитив
  - Существительные → ед.ч. им.п.
- ФИНАЛЬНАЯ ПРОВЕРКА: добавлен пункт 6 про словарную форму

**Agent #2 — изменения:**
- `highlight`: "фраза В БАЗОВОЙ ФОРМЕ" (phrasal verbs → инфинитив)
- `highlight_translation`: добавлена словарная форма русского перевода
- `context`: уточнено что фраза в тексте может быть в другой грамм. форме

### Уровень 2: Код — подстраховка

AI не всегда следует промпту (доказано: pertains, adapted). Код должен подстраховывать.

#### 2a. Английская лемма на карточке

**Что:** Показывать spaCy-лемму в заголовке карточки вместо сырого вывода AI.

**Где:** `analysis_orchestrator.py:293`

**Сейчас:**
```python
highlight = Highlight(
    highlight=word,  # Оригинальное слово - то что видит пользователь
    ...
)
```

**Надо:**
```python
highlight = Highlight(
    highlight=word_lemma,  # spaCy-лемма для отображения
    ...
)
```

**Нюанс:** Для фраз spaCy лемматизирует пословно ("popped up" → "pop up") — корректно для phrasal verbs.

**Нюанс 2:** Сейчас для одиночных слов, если словарь знает оригинал, `final_lemma = word.lower()` (строка 245). Это значит что если AI вернул "intriguing" и словарь знает "intriguing", лемма = "intriguing" (не "intrigue"). Для причастий/герундий это корректно (промпт просит оставлять как есть). Но нужно проверить что spaCy тоже оставляет причастия как есть при отдельном слове без контекста.

#### 2b. Русская лемматизация (pymorphy2)

**Что:** Нормализовать `highlight_translation` через pymorphy2.

**Зависимость:** `pymorphy2` — нужно добавить в `requirements.txt`.

**Где добавить:** `utils/lemmatizer.py` — новая функция `lemmatize_russian()`.

**Логика:**
```python
import pymorphy2

_morph = None

def _get_morph():
    global _morph
    if _morph is None:
        _morph = pymorphy2.MorphAnalyzer()
    return _morph

def lemmatize_russian(text: str) -> str:
    """
    Нормализует русский текст в словарную форму.

    Для одиночных слов:
    - Прилагательные/причастия → м.р. ед.ч. им.п.
    - Глаголы → инфинитив
    - Существительные → ед.ч. им.п.

    Для фраз:
    - Лемматизируем первое слово (основной глагол/прилагательное)
    - Остальные слова оставляем как есть

    Примеры:
    - "захватывающие" → "захватывающий"
    - "адаптировались" → "адаптироваться"
    - "засыпали вопросами" → "засыпать вопросами"
    """
    if not text or not text.strip():
        return text

    morph = _get_morph()
    words = text.strip().split()

    if len(words) == 1:
        # Одиночное слово — полная нормализация
        parsed = morph.parse(words[0])[0]
        return parsed.normal_form
    else:
        # Фраза — лемматизируем первое слово
        parsed = morph.parse(words[0])[0]
        words[0] = parsed.normal_form
        return ' '.join(words)
```

**Где вызывать:** `analysis_orchestrator.py`, в `_dict_to_highlight()`, после получения `highlight_translation`:
```python
main_translation = highlight_dict.get('highlight_translation', '').strip()
main_translation = lemmatize_russian(main_translation)  # Нормализуем
```

#### 2c. Пересмотр логики final_lemma (опционально)

Сейчас (строка 245): если словарь знает оригинал → `final_lemma = word.lower()`.
Это значит: AI вернул "pertains", словарь знает "pertains" → `final_lemma = "pertains"` (не spaCy-лемма "pertain").

Возможно стоит **всегда использовать spaCy-лемму** для `final_lemma`, а словарь запрашивать отдельно по обоим вариантам.

---

## POS (часть речи) — отложено

**Решение:** Не добавлять POS в промпты сейчас.

**Причина:**
- pymorphy2 сам определяет POS русского слова
- spaCy сам определяет POS английского слова
- Из 13 примеров только 2 требуют POS от AI-агента
- Добавление POS в промпт усложняет инструкции и может снизить качество основных полей

**Когда пересмотреть:** После внедрения Уровня 1 + 2, если останутся проблемы с неправильной частью речи.

---

## План действий

### Этап 1: Промпты (без деплоя)
- [ ] Применить промпт v2.0 для Agent #1 в AI Studio
- [ ] Применить промпт v2.0 для Agent #2 в AI Studio
- [ ] Протестировать на нескольких текстах
- [ ] Оценить: насколько AI стал лучше возвращать словарные формы

### Этап 2: Код — русская лемматизация
- [ ] Добавить `pymorphy2` в `requirements.txt`
- [ ] Добавить `lemmatize_russian()` в `utils/lemmatizer.py`
- [ ] Вызывать `lemmatize_russian()` для `highlight_translation` в `_dict_to_highlight()`
- [ ] Протестировать на собранных примерах

### Этап 3: Код — английская лемма на карточке
- [ ] Изменить `highlight=word` → `highlight=word_lemma` в `analysis_orchestrator.py:293`
- [ ] Проверить что spaCy корректно обрабатывает причастия/герундии отдельно от контекста
- [ ] Протестировать

### Этап 4: Тестирование
- [ ] Прогнать все 13 собранных примеров
- [ ] Проверить что нет регрессий (правильные результаты не сломались)
- [ ] Деплой

---

## Связанные коммиты

- `e9d0f10` — refactor: fix lemma logic and remove dead code (удалён pymorphy2)
- `b2f6e4f` — fix: always use spaCy lemma, dictionary only for translations
- `bba1d67` — feat: smart lemma selection based on dictionary lookup
