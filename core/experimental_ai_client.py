#!/usr/bin/env python3
"""
üß™ –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê–õ–¨–ù–´–ô –∫–ª–∏–µ–Ω—Ç –¥–ª—è dual-prompt –∞–Ω–∞–ª–∏–∑–∞
–ö–æ–ø–∏—è YandexAIClient —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –¥–≤—É—Ö –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤
"""

import os
import re
import requests
import json
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

@dataclass
class LinguisticHighlight:
    """–õ–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ö–∞–π–ª–∞–π—Ç"""
    highlight: str              # –°–ª–æ–≤–æ –∏–ª–∏ —Ñ—Ä–∞–∑–∞
    context: str               # –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞
    context_translation: str   # –ü–µ—Ä–µ–≤–æ–¥ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    english_example: str       # –ü—Ä–∏–º–µ—Ä –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º
    russian_example: str       # –ü—Ä–∏–º–µ—Ä –Ω–∞ —Ä—É—Å—Å–∫–æ–º
    cefr_level: str           # A1-C2
    importance_score: int      # 0-100
    dictionary_meanings: List[str]  # –°–ª–æ–≤–∞—Ä–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    why_interesting: str       # –ü–æ—á–µ–º—É –∏–Ω—Ç–µ—Ä–µ—Å–µ–Ω –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è
    
    def to_dict(self) -> Dict[str, Any]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è JSON"""
        from dataclasses import asdict
        return asdict(self)

class ExperimentalYandexAIClient:
    """üß™ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è dual-prompt –∞–Ω–∞–ª–∏–∑–∞"""
    
    def __init__(self):
        self.folder_id = os.getenv('YANDEX_FOLDER_ID')
        self.iam_token = self._get_iam_token()
        self.gpt_url = "https://llm.api.cloud.yandex.net/foundationModels/v1/completion"
        self.translate_url = "https://translate.api.cloud.yandex.net/translate/v2/translate"
        
    def _get_iam_token(self) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç IAM —Ç–æ–∫–µ–Ω –¥–ª—è Yandex Cloud"""
        return os.getenv('YANDEX_IAM_TOKEN', '')
    
    async def analyze_dual_highlights(self, text: str) -> Dict[str, List[LinguisticHighlight]]:
        """
        üß™ –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê–õ–¨–ù–´–ô: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –¥–≤—É–º—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: {"words": [...], "phrases": [...]}
        """
        print(f"üß™ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π dual-prompt –∞–Ω–∞–ª–∏–∑...", flush=True)
        
        try:
            # –î–≤–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞ –∫ Yandex GPT
            words_prompt = self._create_words_prompt(text)
            phrases_prompt = self._create_phrases_prompt(text)
            
            # –ó–∞–ø—Ä–æ—Å—ã –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ä–µ—Å—É—Ä—Å–æ–≤
            words_response = await self._request_yandex_gpt(words_prompt)
            phrases_response = await self._request_yandex_gpt(phrases_prompt)
            
            # –ü–∞—Ä—Å–∏–º –æ–±–∞ –æ—Ç–≤–µ—Ç–∞
            words = self._parse_gpt_response(words_response)
            phrases = self._parse_gpt_response(phrases_response)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–≤–æ–¥—ã
            words = await self._add_translations(words)
            phrases = await self._add_translations(phrases)
            
            result = {
                "words": words,
                "phrases": phrases
            }
            
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(words)} —Å–ª–æ–≤ –∏ {len(phrases)} —Ñ—Ä–∞–∑", flush=True)
            return result
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}", flush=True)
            return {"words": [], "phrases": []}
    
    def _create_words_prompt(self, text: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–ª–æ–≤ (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π)"""
        return f"""
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π –∞–Ω–≥–ª–∏–π—Å–∫–æ–π –ª–µ–∫—Å–∏–∫–µ, –∫–æ—Ç–æ—Ä–∞—è –¥–µ–ª–∞–µ—Ç —Ä–µ—á—å –≤—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω–æ–π, –Ω–∞—Ç—É—Ä–∞–ª—å–Ω–æ–π –∏ —Å—Ç–∏–ª—å–Ω–æ–π. –ù–∞–π–¥–∏ –í–°–ï —Å–ª–æ–≤–∞ –∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–∞, –∫–æ—Ç–æ—Ä—ã–µ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å—Ç–æ—è—Ç –∏–∑—É—á–µ–Ω–∏—è.

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —Ç–µ–∫—Å—Ç:
"{text}"

–ë–†–ê–¢–¨ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç):
- –í—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω—ã–µ, —Ç–æ—á–Ω—ã–µ, "–∂–∏–≤—ã–µ" —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–º –º–µ–¥–∏–∞-–∫–æ–Ω—Ç–µ–Ω—Ç–µ.
- –°–∏–ª—å–Ω—ã–µ –∫–æ–ª–ª–æ–∫–∞—Ü–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä: "compelling argument", "sheer determination").
- –ò–¥–∏–æ–º—ã, –º–µ—Ç–∞—Ñ–æ—Ä—ã, —É—Å—Ç–æ–π—á–∏–≤—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è.
- –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ñ—Ä–∞–∑–æ–≤—ã–µ –≥–ª–∞–≥–æ–ª—ã.
- –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã, –µ—Å–ª–∏ –æ–Ω–∏ —à–∏—Ä–æ–∫–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è (–Ω–∞–ø—Ä–∏–º–µ—Ä: "leverage", "scalability", "breakthrough").

–ù–ï –ë–†–ê–¢–¨:
- –£–∑–∫—É—é, —Å—É—Ö—É—é —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é, –ø–æ–Ω—è—Ç–Ω—É—é —Ç–æ–ª—å–∫–æ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞–º.
- –ß–∞—Å—Ç–æ—Ç–Ω—É—é –±–∞–∑–æ–≤—É—é –ª–µ–∫—Å–∏–∫—É (–ø—Ä–æ—Å—Ç—ã–µ —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –≤—Å–µ –∑–Ω–∞—é—Ç).
- –°–ø–∏—Å–∫–∏ —Å–ª–æ–≤, –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—è —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é.
- –î–ª–∏–Ω–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è –∏–ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.

–¢–†–ï–ë–û–í–ê–ù–ò–Ø:
- –ë–µ—Ä–∏ –º–∞–∫—Å–∏–º—É–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –ø–æ–ª–µ–∑–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π. –ï—Å–ª–∏ —Å–æ–º–Ω–µ–≤–∞–µ—à—å—Å—è ‚Äî –±–µ—Ä–∏.
- "highlight" –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º –∏–ª–∏ –∫–æ—Ä–æ—Ç–∫–æ–π —Ñ—Ä–∞–∑–æ–π.
- "context" ‚Äî —Ç–æ–ª—å–∫–æ –û–î–ù–û –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞, –∫–æ—Ç–æ—Ä–æ–µ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—ã–±—Ä–∞–Ω–Ω–æ–µ —Å–ª–æ–≤–æ/—Ñ—Ä–∞–∑—É. 
- –í–ê–ñ–ù–û: —Å–ª–æ–≤–æ/—Ñ—Ä–∞–∑–∞ –∏–∑ "highlight" –¥–æ–ª–∂–Ω–æ —Ç–æ—á–Ω–æ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –≤ "context".
- "context_translation" ‚Äî —ç—Ç–æ –ø–µ—Ä–µ–≤–æ–¥ –¢–û–õ–¨–ö–û –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Å–ª–æ–≤–∞/–≤—ã—Ä–∞–∂–µ–Ω–∏—è (–∫—Ä–∞—Ç–∫–æ, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π).

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ ‚Äî —Ç–æ–ª—å–∫–æ –º–∞—Å—Å–∏–≤ JSON:
[
  {{
    "highlight": "—Å–ª–æ–≤–æ –∏–ª–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ",
    "context": "–æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞",
    "context_translation": "–ø–µ—Ä–µ–≤–æ–¥ —Å–ª–æ–≤–∞/–≤—ã—Ä–∞–∂–µ–Ω–∏—è"
  }}
]

–ü–µ—Ä–µ–¥ —Ç–µ–º –∫–∞–∫ –≤–µ—Ä–Ω—É—Ç—å –æ—Ç–≤–µ—Ç:
–ü—Ä–æ–≤–µ—Ä—å, —á—Ç–æ –±–∞–∑–æ–≤—ã–µ –∏ —É–∑–∫–æ—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å–ª–æ–≤–∞ –∏—Å–∫–ª—é—á–µ–Ω—ã, –∞ –ª—É—á—à–∏–µ –≤—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –≤–∫–ª—é—á–µ–Ω—ã.

–í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –º–∞—Å—Å–∏–≤ JSON.
"""
    
    def _create_phrases_prompt(self, text: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –≥–ª–∞–≥–æ–ª—å–Ω—ã—Ö –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π"""
        return f"""
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–º —Ä–µ—á–µ–≤—ã–º –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞. –ù–∞–π–¥–∏ –°–¢–ò–õ–¨–ù–´–ï –ì–õ–ê–ì–û–õ–¨–ù–´–ï –§–†–ê–ó–´ –∏ –í–´–†–ê–ó–ò–¢–ï–õ–¨–ù–´–ï –†–ï–ß–ï–í–´–ï –û–ë–û–†–û–¢–´, –∫–æ—Ç–æ—Ä—ã–µ –¥–µ–ª–∞—é—Ç —Ä–µ—á—å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–π –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–π.

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —Ç–µ–∫—Å—Ç:
"{text}"

–ë–†–ê–¢–¨ (—Ç–æ–ª—å–∫–æ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ 3+ —Å–ª–æ–≤):
- –ò–∑–æ—â—Ä–µ–Ω–Ω—ã–µ —Ä–µ—á–µ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å –≥–ª–∞–≥–æ–ª–∞–º–∏
- –°—Ç–∏–ª—å–Ω—ã–µ –≥–ª–∞–≥–æ–ª—å–Ω—ã–µ —Å–≤—è–∑–∫–∏ –∏ –æ–±–æ—Ä–æ—Ç—ã  
- –í—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω—ã–µ –º–æ–¥–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
- –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ä–µ—á–µ–≤—ã–µ –æ–±–æ—Ä–æ—Ç—ã
- –°–ª–æ–∂–Ω—ã–µ —Ñ—Ä–∞–∑–æ–≤—ã–µ –≥–ª–∞–≥–æ–ª—ã —Å –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è–º–∏

–ù–ï –ë–†–ê–¢–¨:
- –ë–∞–∑–æ–≤—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ —É—Ä–æ–≤–Ω—è —à–∫–æ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã
- –ü—Ä–æ—Å—Ç—ã–µ –º–æ–¥–∞–ª—å–Ω—ã–µ –≥–ª–∞–≥–æ–ª—ã —Å –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º
- –ü—Ä–∏–º–∏—Ç–∏–≤–Ω—ã–µ —Å–≤—è–∑–∫–∏ –∏ –ø–µ—Ä–µ—Ö–æ–¥—ã
- –û—á–µ–≤–∏–¥–Ω—ã–µ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã–µ —Ñ—Ä–∞–∑—ã

–§–û–ö–£–°: –¢–æ–ª—å–∫–æ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–¥–µ–ª—è—é—Ç —Ä–µ—á—å –∫–∞–∫ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—É—é –∏ —Å—Ç–∏–ª—å–Ω—É—é. –ò—â–∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã.

JSON —Ñ–æ—Ä–º–∞—Ç: [{{"highlight": "–ø—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Ñ—Ä–∞–∑–∞", "context": "–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ", "context_translation": "–ø–µ—Ä–µ–≤–æ–¥ —Ñ—Ä–∞–∑—ã"}}]
"""
    
    async def _request_yandex_gpt(self, prompt: str) -> Dict[str, Any]:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ Yandex GPT"""
        headers = {
            "Authorization": f"Bearer {self.iam_token}",
            "Content-Type": "application/json"
        }
        
        data = {
            "modelUri": f"gpt://{self.folder_id}/yandexgpt-lite",
            "completionOptions": {
                "stream": False,
                "temperature": 0.3,
                "maxTokens": 2000
            },
            "messages": [
                {
                    "role": "user",
                    "text": prompt
                }
            ]
        }
        
        # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ (1 —Ç–æ–∫–µ–Ω ‚âà 4 —Å–∏–º–≤–æ–ª–∞ –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ)
        input_tokens = len(prompt) // 4
        print(f"üí∞ –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ {input_tokens} –≤—Ö–æ–¥–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤", flush=True)
        
        # –†–µ–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫ Yandex GPT
        if not self.iam_token:
            print("‚ö†Ô∏è Yandex IAM —Ç–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É—é fallback")
            return {"result": {"alternatives": [{"message": {"text": "[]"}}]}}
        
        try:
            response = requests.post(self.gpt_url, headers=headers, json=data, timeout=60)
            
            if response.status_code == 200:
                result = response.json()
                # –ü–æ–¥—Å—á–µ—Ç –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
                response_text = result.get("result", {}).get("alternatives", [{}])[0].get("message", {}).get("text", "")
                output_tokens = len(response_text) // 4
                total_cost = (input_tokens * 0.0006) + (output_tokens * 0.0012)  # –ü—Ä–∏–º–µ—Ä–Ω—ã–µ —Ü–µ–Ω—ã –≤ —Ä—É–±–ª—è—Ö –∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤
                print(f"üí∞ ~{output_tokens} –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ | –°—Ç–æ–∏–º–æ—Å—Ç—å: ~{total_cost:.3f}‚ÇΩ", flush=True)
                return result
            else:
                print(f"‚ö†Ô∏è Yandex GPT –æ—à–∏–±–∫–∞ {response.status_code}: {response.text[:200]}...")
                return {"result": {"alternatives": [{"message": {"text": "[]"}}]}}
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ Yandex GPT: {e}")
            return {"result": {"alternatives": [{"message": {"text": "[]"}}]}}
    
    def _parse_gpt_response(self, response: Dict[str, Any]) -> List[LinguisticHighlight]:
        """–ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç –æ—Ç Yandex GPT"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
            text = response["result"]["alternatives"][0]["message"]["text"]
            
            # –û—á–∏—â–∞–µ–º –æ—Ç markdown —Ä–∞–∑–º–µ—Ç–∫–∏
            text = text.strip()
            if text.startswith("```"):
                text = text.split("```")[1]  # –£–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–π ```
                if text.startswith("json"):
                    text = text[4:]  # –£–±–∏—Ä–∞–µ–º "json"
                text = text.strip()
            if text.endswith("```"):
                text = text[:-3].strip()
            
            # –ü–∞—Ä—Å–∏–º JSON
            highlights_data = json.loads(text)
            
            highlights = []
            for item in highlights_data:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ö–∞–π–ª–∞–π—Ç –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –µ—Å—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
                highlight_text = item["highlight"].lower()
                context_text = item["context"].lower()
                
                # –î–ª—è —Ñ—Ä–∞–∑ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ —á–∞—Å—Ç—è–º
                words_in_context = True
                if ' ' in highlight_text:
                    for word in highlight_text.split():
                        if len(word) > 2 and word not in context_text:
                            words_in_context = False
                            break
                else:
                    # –î–ª—è –æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞
                    words_in_context = highlight_text in context_text
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ö–∞–π–ª–∞–π—Ç—ã, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
                if not words_in_context:
                    print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é —Ö–∞–π–ª–∞–π—Ç '{item['highlight']}' - –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ")
                    continue
                
                highlight = LinguisticHighlight(
                    highlight=item["highlight"],
                    context=item["context"],
                    context_translation=item.get("context_translation", ""),
                    english_example=f"Example: {item['context']}",
                    russian_example="",  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ —á–µ—Ä–µ–∑ Yandex Translate
                    cefr_level="C1",  # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ - –≤—Å–µ —Å–ª–æ–≤–∞ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ
                    importance_score=85,  # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                    dictionary_meanings=[],  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ —á–µ—Ä–µ–∑ Yandex Translate
                    why_interesting="–í—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω–∞—è –ª–µ–∫—Å–∏–∫–∞ –¥–ª—è —Å—Ç–∏–ª—å–Ω–æ–π —Ä–µ—á–∏"
                )
                highlights.append(highlight)
            
            return highlights
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ GPT –æ—Ç–≤–µ—Ç–∞: {e}", flush=True)
            return []
    
    async def _add_translations(self, highlights: List[LinguisticHighlight]) -> List[LinguisticHighlight]:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–ª–æ–≤–∞—Ä–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —á–µ—Ä–µ–∑ Yandex Translate"""
        for highlight in highlights:
            try:
                # –ü–æ–ª—É—á–∞–µ–º —Å–ª–æ–≤–∞—Ä–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Å–ª–æ–≤–∞
                dictionary_meanings = self._get_dictionary_meanings(highlight.highlight)
                highlight.dictionary_meanings = dictionary_meanings
                
                # –ü–µ—Ä–µ–≤–æ–¥–∏–º —Ç–æ–ª—å–∫–æ —Å–∞–º —Ö–∞–π–ª–∞–π—Ç, –∞ –Ω–µ –≤–µ—Å—å –ø—Ä–∏–º–µ—Ä
                highlight.russian_example = await self._translate_text(highlight.highlight)
                
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ª–æ–≤–∞—Ä–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è '{highlight.highlight}': {e}", flush=True)
                highlight.dictionary_meanings = [f"–ó–Ω–∞—á–µ–Ω–∏–µ: {highlight.highlight}"]
                highlight.russian_example = f"–ü–µ—Ä–µ–≤–æ–¥: {highlight.highlight}"
        
        return highlights
    
    def _get_dictionary_meanings(self, word: str) -> List[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ª–æ–≤–∞—Ä–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å–ª–æ–≤–∞ —á–µ—Ä–µ–∑ Free Dictionary API"""
        try:            
            # –û—á–∏—â–∞–µ–º —Å–ª–æ–≤–æ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
            clean_word = re.sub(r'[^a-zA-Z\s-]', '', word.strip().lower())
            if not clean_word:
                return []
            
            # –ù–µ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–ª—è —Ñ—Ä–∞–∑ (–±–æ–ª—å—à–µ –æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞)
            if ' ' in clean_word:
                return []
            
            url = f"https://api.dictionaryapi.dev/api/v2/entries/en/{clean_word}"
            
            response = requests.get(url, timeout=10)
            if response.status_code == 200:
                data = response.json()
                meanings = []
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏–∑ API –æ—Ç–≤–µ—Ç–∞
                for entry in data[:2]:  # –ü–µ—Ä–≤—ã–µ 2 –∑–∞–ø–∏—Å–∏
                    for meaning in entry.get('meanings', [])[:2]:  # –ü–µ—Ä–≤—ã–µ 2 –∑–Ω–∞—á–µ–Ω–∏—è
                        part_of_speech = meaning.get('partOfSpeech', '')
                        for definition in meaning.get('definitions', [])[:1]:  # –ü–µ—Ä–≤–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
                            def_text = definition.get('definition', '')
                            if def_text:
                                # –ü–µ—Ä–µ–≤–æ–¥–∏–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–∏–π
                                russian_def = self._translate_definition_sync(def_text)
                                meanings.append(russian_def)
                
                return meanings[:3] if meanings else []
            else:
                return []
                        
        except Exception as e:
            return []

    def _translate_definition_sync(self, definition: str) -> str:
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç –∞–Ω–≥–ª–∏–π—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —á–µ—Ä–µ–∑ Yandex Translate (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)"""
        try:
            headers = {
                "Authorization": f"Bearer {self.iam_token}",
                "Content-Type": "application/json"
            }
            
            data = {
                "folderId": self.folder_id,
                "texts": [definition],
                "sourceLanguageCode": "en",
                "targetLanguageCode": "ru"
            }
            
            response = requests.post(
                "https://translate.api.cloud.yandex.net/translate/v2/translate",
                headers=headers, 
                json=data, 
                timeout=10
            )
            
            if response.status_code == 200:
                result = response.json()
                translation = result["translations"][0]["text"]
                return translation
            else:
                return definition  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –µ—Å–ª–∏ –ø–µ—Ä–µ–≤–æ–¥ –Ω–µ —É–¥–∞–ª—Å—è
                
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è: {e}", flush=True)
            return definition  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª

    async def _translate_text(self, text: str) -> str:
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ Yandex Translate"""
        try:
            # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
            return f"[–ü–ï–†–ï–í–û–î: {text}]"
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Yandex Translate: {e}", flush=True)
            return f"[–ü–ï–†–ï–í–û–î: {text}]"

def test_experimental_client():
    """–¢–µ—Å—Ç —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞"""
    import asyncio
    
    async def run_test():
        print("üß™ –¢–ï–°–¢ EXPERIMENTAL CLIENT")
        print("=" * 50)
        
        client = ExperimentalYandexAIClient()
        
        test_text = """
        Machine learning algorithms analyze complex patterns in massive datasets. 
        These sophisticated methods revolutionize artificial intelligence research.
        Scientists develop innovative approaches to solve computational problems.
        """
        
        result = await client.analyze_dual_highlights(test_text.strip())
        
        print(f"\nüìö –ù–∞–π–¥–µ–Ω–æ {len(result['words'])} —Å–ª–æ–≤ –∏ {len(result['phrases'])} —Ñ—Ä–∞–∑:")
        
        print(f"\nüî§ –°–õ–û–í–ê ({len(result['words'])}):")
        for i, h in enumerate(result['words']):
            print(f"{i+1}. {h.highlight}")
        
        print(f"\nüí¨ –§–†–ê–ó–´ ({len(result['phrases'])}):")
        for i, h in enumerate(result['phrases']):
            print(f"{i+1}. {h.highlight}")
        
        print("\n‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω!")
    
    asyncio.run(run_test())

if __name__ == "__main__":
    test_experimental_client()