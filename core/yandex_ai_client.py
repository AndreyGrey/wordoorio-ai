#!/usr/bin/env python3
"""
–ö–ª–∏–µ–Ω—Ç –¥–ª—è Yandex AI Studio API
–ü–æ–¥–¥–µ—Ä–∂–∫–∞ Yandex GPT –∏ Yandex Translate
"""

import os
import re
import requests
import json
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, field
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

@dataclass
class LinguisticHighlight:
    """–õ–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ö–∞–π–ª–∞–π—Ç (legacy - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Highlight –∏–∑ contracts)"""
    highlight: str              # –°–ª–æ–≤–æ –∏–ª–∏ —Ñ—Ä–∞–∑–∞
    context: str               # –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞
    highlight_translation: str  # –ü–µ—Ä–µ–≤–æ–¥ —Å–ª–æ–≤–∞/—Ñ—Ä–∞–∑—ã
    cefr_level: str           # A1-C2
    importance_score: int      # 0-100
    dictionary_meanings: List[str] = field(default_factory=list)  # –°–ª–æ–≤–∞—Ä–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    why_interesting: str = ""  # –ü–æ—á–µ–º—É –∏–Ω—Ç–µ—Ä–µ—Å–µ–Ω –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è
    
    def to_dict(self) -> Dict[str, Any]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è JSON"""
        from dataclasses import asdict
        return asdict(self)

class YandexAIClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Yandex AI Studio"""

    # –°–ø–∏—Å–æ–∫ –ø—Ä–∏–º–∏—Ç–∏–≤–Ω—ã—Ö/–±–∞–∑–æ–≤—ã—Ö —Å–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä—è—Ç—å –≤ —Å–ª–æ–≤–∞—Ä–µ
    PRIMITIVE_WORDS = {
        # –ê—Ä—Ç–∏–∫–ª–∏
        'a', 'an', 'the',
        # –ü—Ä–µ–¥–ª–æ–≥–∏
        'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'from', 'about', 'as',
        'into', 'through', 'during', 'before', 'after', 'above', 'below', 'between',
        'under', 'over', 'across', 'off', 'out', 'up', 'down',
        # –ú–µ—Å—Ç–æ–∏–º–µ–Ω–∏—è
        'i', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them',
        'my', 'your', 'his', 'her', 'its', 'our', 'their', 'mine', 'yours', 'hers', 'ours', 'theirs',
        'this', 'that', 'these', 'those', 'who', 'what', 'which', 'whom', 'whose',
        # –ë–∞–∑–æ–≤—ã–µ –≥–ª–∞–≥–æ–ª—ã
        'be', 'is', 'are', 'was', 'were', 'been', 'being', 'am',
        'have', 'has', 'had', 'having',
        'do', 'does', 'did', 'doing', 'done',
        'will', 'would', 'could', 'should', 'may', 'might', 'can', 'must',
        'get', 'got', 'getting', 'go', 'goes', 'went', 'going', 'gone',
        'make', 'makes', 'made', 'making',
        'take', 'takes', 'took', 'taking', 'taken',
        'come', 'comes', 'came', 'coming',
        'give', 'gives', 'gave', 'giving', 'given',
        'know', 'knows', 'knew', 'knowing', 'known',
        'see', 'sees', 'saw', 'seeing', 'seen',
        'use', 'uses', 'used', 'using',
        'find', 'finds', 'found', 'finding',
        'tell', 'tells', 'told', 'telling',
        'ask', 'asks', 'asked', 'asking',
        'want', 'wants', 'wanted', 'wanting',
        'need', 'needs', 'needed', 'needing',
        'try', 'tries', 'tried', 'trying',
        'call', 'calls', 'called', 'calling',
        'put', 'puts', 'putting',
        'say', 'says', 'said', 'saying',
        'keep', 'keeps', 'kept', 'keeping',
        'let', 'lets', 'letting',
        'begin', 'begins', 'began', 'beginning', 'begun',
        'seem', 'seems', 'seemed', 'seeming',
        'help', 'helps', 'helped', 'helping',
        'talk', 'talks', 'talked', 'talking',
        'turn', 'turns', 'turned', 'turning',
        'start', 'starts', 'started', 'starting',
        'show', 'shows', 'showed', 'showing', 'shown',
        'hear', 'hears', 'heard', 'hearing',
        'play', 'plays', 'played', 'playing',
        'run', 'runs', 'ran', 'running',
        'move', 'moves', 'moved', 'moving',
        'like', 'likes', 'liked', 'liking',
        'live', 'lives', 'lived', 'living',
        'believe', 'believes', 'believed', 'believing',
        'bring', 'brings', 'brought', 'bringing',
        'happen', 'happens', 'happened', 'happening',
        'write', 'writes', 'wrote', 'writing', 'written',
        'sit', 'sits', 'sat', 'sitting',
        'stand', 'stands', 'stood', 'standing',
        'lose', 'loses', 'lost', 'losing',
        'pay', 'pays', 'paid', 'paying',
        'meet', 'meets', 'met', 'meeting',
        'include', 'includes', 'included', 'including',
        'continue', 'continues', 'continued', 'continuing',
        'set', 'sets', 'setting',
        'learn', 'learns', 'learned', 'learning', 'learnt',
        'change', 'changes', 'changed', 'changing',
        'lead', 'leads', 'led', 'leading',
        'understand', 'understands', 'understood', 'understanding',
        'watch', 'watches', 'watched', 'watching',
        'follow', 'follows', 'followed', 'following',
        'stop', 'stops', 'stopped', 'stopping',
        'create', 'creates', 'created', 'creating',
        'speak', 'speaks', 'spoke', 'speaking', 'spoken',
        'read', 'reads', 'reading',
        'spend', 'spends', 'spent', 'spending',
        'grow', 'grows', 'grew', 'growing', 'grown',
        'open', 'opens', 'opened', 'opening',
        'walk', 'walks', 'walked', 'walking',
        'win', 'wins', 'won', 'winning',
        'teach', 'teaches', 'taught', 'teaching',
        'offer', 'offers', 'offered', 'offering',
        'remember', 'remembers', 'remembered', 'remembering',
        'consider', 'considers', 'considered', 'considering',
        'appear', 'appears', 'appeared', 'appearing',
        'buy', 'buys', 'bought', 'buying',
        'serve', 'serves', 'served', 'serving',
        'die', 'dies', 'died', 'dying',
        'send', 'sends', 'sent', 'sending',
        'build', 'builds', 'built', 'building',
        'stay', 'stays', 'stayed', 'staying',
        'fall', 'falls', 'fell', 'falling', 'fallen',
        'cut', 'cuts', 'cutting',
        'reach', 'reaches', 'reached', 'reaching',
        'kill', 'kills', 'killed', 'killing',
        'raise', 'raises', 'raised', 'raising',
        'pass', 'passes', 'passed', 'passing',
        'sell', 'sells', 'sold', 'selling',
        'decide', 'decides', 'decided', 'deciding',
        'return', 'returns', 'returned', 'returning',
        'explain', 'explains', 'explained', 'explaining',
        'hope', 'hopes', 'hoped', 'hoping',
        'develop', 'develops', 'developed', 'developing',
        'carry', 'carries', 'carried', 'carrying',
        'break', 'breaks', 'broke', 'breaking', 'broken',
        # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–µ
        'good', 'better', 'best', 'bad', 'worse', 'worst', 'big', 'bigger', 'biggest',
        'small', 'smaller', 'smallest', 'new', 'newer', 'newest', 'old', 'older', 'oldest',
        'great', 'greater', 'greatest', 'high', 'higher', 'highest', 'low', 'lower', 'lowest',
        'long', 'longer', 'longest', 'short', 'shorter', 'shortest', 'early', 'earlier', 'earliest',
        'late', 'later', 'latest', 'young', 'younger', 'youngest', 'important', 'more', 'most',
        'large', 'larger', 'largest', 'little', 'less', 'least', 'own', 'other', 'another',
        'same', 'few', 'public', 'able', 'such', 'only', 'first', 'last', 'next', 'different',
        'many', 'much', 'several', 'every', 'each', 'some', 'any', 'all', 'both', 'either',
        'neither', 'right', 'left', 'true', 'false', 'real', 'sure', 'full', 'half', 'whole',
        'free', 'ready', 'easy', 'hard', 'simple', 'clear', 'close', 'open', 'strong', 'weak',
        # –ë–∞–∑–æ–≤—ã–µ –Ω–∞—Ä–µ—á–∏—è
        'very', 'too', 'so', 'just', 'now', 'then', 'here', 'there', 'where', 'when', 'why',
        'how', 'also', 'well', 'back', 'only', 'even', 'still', 'already', 'yet', 'again',
        'never', 'always', 'often', 'sometimes', 'usually', 'today', 'tomorrow', 'yesterday',
        'soon', 'far', 'away', 'together', 'however', 'perhaps', 'maybe', 'quite', 'rather',
        'almost', 'enough', 'too', 'nearly', 'probably', 'possibly', 'certainly', 'definitely',
        # –ë–∞–∑–æ–≤—ã–µ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ
        'time', 'year', 'day', 'way', 'man', 'woman', 'child', 'children', 'people', 'person',
        'thing', 'things', 'life', 'world', 'hand', 'part', 'place', 'case', 'week', 'company',
        'system', 'program', 'question', 'work', 'government', 'number', 'night', 'point', 'home',
        'water', 'room', 'mother', 'father', 'area', 'money', 'story', 'fact', 'month', 'lot',
        'right', 'study', 'book', 'eye', 'job', 'word', 'business', 'issue', 'side', 'kind',
        'head', 'house', 'service', 'friend', 'problem', 'power', 'end', 'member', 'law', 'car',
        'city', 'name', 'team', 'minute', 'idea', 'body', 'information', 'back', 'parent', 'face',
        'others', 'level', 'office', 'door', 'health', 'art', 'war', 'history', 'party', 'result',
        'change', 'morning', 'reason', 'research', 'girl', 'guy', 'moment', 'air', 'teacher', 'force',
        'education',
        # –°–æ—é–∑—ã
        'and', 'or', 'but', 'so', 'because', 'if', 'when', 'while', 'although', 'though',
        'since', 'until', 'unless', 'than', 'whether', 'nor', 'yet',
        # –î—Ä—É–≥–∏–µ —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞
        'not', 'no', 'yes', 'ok', 'okay', 'please', 'thank', 'thanks', 'sorry', 'well',
    }

    def __init__(self):
        self.folder_id = os.getenv('YANDEX_FOLDER_ID')
        self.iam_token = self._get_iam_token()
        self.dict_api_key = os.getenv('YANDEX_DICT_API_KEY', '')
        self.gpt_url = "https://llm.api.cloud.yandex.net/foundationModels/v1/completion"
        self.translate_url = "https://translate.api.cloud.yandex.net/translate/v2/translate"
        self.dict_url = "https://dictionary.yandex.net/api/v1/dicservice.json/lookup"

    def _get_iam_token(self) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç IAM —Ç–æ–∫–µ–Ω –¥–ª—è Yandex Cloud

        –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:
        1. Environment variable (–¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏)
        2. Metadata Service (–¥–ª—è Serverless Container —Å Service Account)
        """
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è (–¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏)
        env_token = os.getenv('YANDEX_IAM_TOKEN', '')
        if env_token:
            return env_token

        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω —á–µ—Ä–µ–∑ Metadata Service (–¥–ª—è Serverless Container)
        try:
            metadata_url = 'http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token'
            headers = {'Metadata-Flavor': 'Google'}  # Yandex Cloud –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Å GCP —Ñ–æ—Ä–º–∞—Ç

            response = requests.get(metadata_url, headers=headers, timeout=5)

            if response.status_code == 200:
                token_data = response.json()
                iam_token = token_data.get('access_token', '')
                print(f"‚úÖ IAM —Ç–æ–∫–µ–Ω –ø–æ–ª—É—á–µ–Ω —á–µ—Ä–µ–∑ Metadata Service", flush=True)
                return iam_token
            else:
                print(f"‚ö†Ô∏è Metadata Service –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {response.status_code}", flush=True)
                return ''

        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–∫–µ–Ω —á–µ—Ä–µ–∑ Metadata Service: {e}", flush=True)
            return ''
    
    async def analyze_linguistic_highlights(self, text: str) -> List[LinguisticHighlight]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –∏ –≤—ã–¥–µ–ª—è–µ—Ç 3-30 –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Ö–∞–π–ª–∞–π—Ç–æ–≤
        """
        print(f"üß† –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ö–∞–π–ª–∞–π—Ç—ã –≤ —Ç–µ–∫—Å—Ç–µ...", flush=True)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ö–∞–π–ª–∞–π—Ç–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞
        word_count = len(text.split())
        if word_count < 20:
            target_count = "3-5"
        elif word_count < 50:
            target_count = "5-10"
        elif word_count < 100:
            target_count = "10-20"
        else:
            target_count = "15-30"
        
        prompt = self._create_highlights_prompt(text, target_count)
        
        try:
            # –ó–∞–ø—Ä–æ—Å –∫ Yandex GPT
            gpt_response = await self._request_yandex_gpt(prompt)
            
            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç –∏ —Å–æ–∑–¥–∞–µ–º —Ö–∞–π–ª–∞–π—Ç—ã
            highlights = self._parse_gpt_response(gpt_response)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–≤–æ–¥—ã —á–µ—Ä–µ–∑ Yandex Translate
            highlights = await self._add_translations(highlights)
            
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(highlights)} —Ö–∞–π–ª–∞–π—Ç–æ–≤", flush=True)
            return highlights
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ö–∞–π–ª–∞–π—Ç–æ–≤: {e}", flush=True)
            # Fallback –Ω–∞ –ø—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑
            return self._fallback_analysis(text)
    
    def _create_phrases_prompt(self, text: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ñ—Ä–∞–∑ –∏ —Å–ª–æ–≤–æ—Å–æ—á–µ—Ç–∞–Ω–∏–π"""
        return f"""
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º—É —è–∑—ã–∫—É. –ù–∞–π–¥–∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ —Å–ª–æ–≤–æ—Å–æ—á–µ—Ç–∞–Ω–∏—è –∏ –Ω–∞—Ç–∏–≤–Ω—ã–µ –æ–±–æ—Ä–æ—Ç—ã —Ä–µ—á–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ ‚Äî —Ñ—Ä–∞–∑—ã, –∫–æ—Ç–æ—Ä—ã–µ –∑–≤—É—á–∞—Ç –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ.

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —Ç–µ–∫—Å—Ç:
"{text}"

–ë–†–ê–¢–¨ (—Ç–æ–ª—å–∫–æ —Ñ—Ä–∞–∑—ã 2+ —Å–ª–æ–≤):
- –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–æ—Å–æ—á–µ—Ç–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –Ω–æ—Å–∏—Ç–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –∫–∞–∫ –µ–¥–∏–Ω–æ–µ —Ü–µ–ª–æ–µ
- –§—Ä–∞–∑–æ–≤—ã–µ –≥–ª–∞–≥–æ–ª—ã –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ  
- –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏ —É—Å—Ç–æ–π—á–∏–≤—ã–µ —Å–æ—á–µ—Ç–∞–Ω–∏—è
- –ò–¥–∏–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ–±–æ—Ä–æ—Ç—ã –∏ —Å–≤—è–∑–∫–∏
- –í—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω—ã–µ —Å–æ—á–µ—Ç–∞–Ω–∏—è, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø–∏—Å—å–º–∞

–ù–ï –ë–†–ê–¢–¨:
- –û—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
- –°–ª—É—á–∞–π–Ω—ã–µ —Å–æ—á–µ—Ç–∞–Ω–∏—è —Å–ª–æ–≤ –±–µ–∑ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏
- –ü—Ä–æ—Å—Ç—ã–µ –ø—Ä–µ–¥–ª–æ–≥–Ω—ã–µ —Ñ—Ä–∞–∑—ã

–ò—â–∏ —Ñ—Ä–∞–∑—ã, –∫–æ—Ç–æ—Ä—ã–µ –∏–∑—É—á–∞—é—â–∏–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –∑–∞—Ö–æ—Ç–µ–ª–∏ –±—ã –∑–∞–ø–æ–º–Ω–∏—Ç—å –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å.

JSON —Ñ–æ—Ä–º–∞—Ç: [{{"highlight": "—Ñ—Ä–∞–∑–∞", "context": "–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ", "highlight_translation": "–ø–µ—Ä–µ–≤–æ–¥ —Ñ—Ä–∞–∑—ã"}}]
"""
    
    def _create_highlights_prompt(self, text: str, target_count: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ö–∞–π–ª–∞–π—Ç–æ–≤"""
        return f"""
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π –∞–Ω–≥–ª–∏–π—Å–∫–æ–π –ª–µ–∫—Å–∏–∫–µ, –∫–æ—Ç–æ—Ä–∞—è –¥–µ–ª–∞–µ—Ç —Ä–µ—á—å –≤—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω–æ–π, –Ω–∞—Ç—É—Ä–∞–ª—å–Ω–æ–π –∏ —Å—Ç–∏–ª—å–Ω–æ–π. –ù–∞–π–¥–∏ –í–°–ï —Å–ª–æ–≤–∞ –∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–∞, –∫–æ—Ç–æ—Ä—ã–µ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å—Ç–æ—è—Ç –∏–∑—É—á–µ–Ω–∏—è.

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —Ç–µ–∫—Å—Ç:
"{text}"

–ë–†–ê–¢–¨ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç):
- –í—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω—ã–µ, —Ç–æ—á–Ω—ã–µ, "–∂–∏–≤—ã–µ" —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–º –º–µ–¥–∏–∞-–∫–æ–Ω—Ç–µ–Ω—Ç–µ.
- –°–∏–ª—å–Ω—ã–µ –∫–æ–ª–ª–æ–∫–∞—Ü–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä: "compelling argument", "sheer determination").
- –ò–¥–∏–æ–º—ã, –º–µ—Ç–∞—Ñ–æ—Ä—ã, —É—Å—Ç–æ–π—á–∏–≤—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è.
- –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ñ—Ä–∞–∑–æ–≤—ã–µ –≥–ª–∞–≥–æ–ª—ã.
- –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã, –µ—Å–ª–∏ –æ–Ω–∏ —à–∏—Ä–æ–∫–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è (–Ω–∞–ø—Ä–∏–º–µ—Ä: "leverage", "scalability", "breakthrough").

–ù–ï –ë–†–ê–¢–¨:
- –£–∑–∫—É—é, —Å—É—Ö—É—é —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é, –ø–æ–Ω—è—Ç–Ω—É—é —Ç–æ–ª—å–∫–æ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞–º.
- –ß–∞—Å—Ç–æ—Ç–Ω—É—é –±–∞–∑–æ–≤—É—é –ª–µ–∫—Å–∏–∫—É (–ø—Ä–æ—Å—Ç—ã–µ —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –≤—Å–µ –∑–Ω–∞—é—Ç).
- –°–ø–∏—Å–∫–∏ —Å–ª–æ–≤, –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—è —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é.
- –î–ª–∏–Ω–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è –∏–ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.

–¢–†–ï–ë–û–í–ê–ù–ò–Ø:
- –ë–µ—Ä–∏ –º–∞–∫—Å–∏–º—É–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –ø–æ–ª–µ–∑–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π. –ï—Å–ª–∏ —Å–æ–º–Ω–µ–≤–∞–µ—à—å—Å—è ‚Äî –±–µ—Ä–∏.
- "highlight" –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º –∏–ª–∏ –∫–æ—Ä–æ—Ç–∫–æ–π —Ñ—Ä–∞–∑–æ–π.
- "context" ‚Äî —Ç–æ–ª—å–∫–æ –û–î–ù–û –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞, –∫–æ—Ç–æ—Ä–æ–µ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—ã–±—Ä–∞–Ω–Ω–æ–µ —Å–ª–æ–≤–æ/—Ñ—Ä–∞–∑—É.
- –í–ê–ñ–ù–û: —Å–ª–æ–≤–æ/—Ñ—Ä–∞–∑–∞ –∏–∑ "highlight" –¥–æ–ª–∂–Ω–æ —Ç–æ—á–Ω–æ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –≤ "context".
- "highlight_translation" ‚Äî —ç—Ç–æ –ø–µ—Ä–µ–≤–æ–¥ –¢–û–õ–¨–ö–û –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Å–ª–æ–≤–∞/–≤—ã—Ä–∞–∂–µ–Ω–∏—è (–∫—Ä–∞—Ç–∫–æ, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π).

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ ‚Äî —Ç–æ–ª—å–∫–æ –º–∞—Å—Å–∏–≤ JSON:
[
  {{
    "highlight": "—Å–ª–æ–≤–æ –∏–ª–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ",
    "context": "–æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞",
    "highlight_translation": "–ø–µ—Ä–µ–≤–æ–¥ —Å–ª–æ–≤–∞/–≤—ã—Ä–∞–∂–µ–Ω–∏—è"
  }}
]

–ü–µ—Ä–µ–¥ —Ç–µ–º –∫–∞–∫ –≤–µ—Ä–Ω—É—Ç—å –æ—Ç–≤–µ—Ç:
–ü—Ä–æ–≤–µ—Ä—å, —á—Ç–æ –±–∞–∑–æ–≤—ã–µ –∏ —É–∑–∫–æ—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å–ª–æ–≤–∞ –∏—Å–∫–ª—é—á–µ–Ω—ã, –∞ –ª—É—á—à–∏–µ –≤—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –≤–∫–ª—é—á–µ–Ω—ã.

–í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –º–∞—Å—Å–∏–≤ JSON.
"""
    
    async def _request_yandex_gpt(self, prompt: str) -> Dict[str, Any]:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ Yandex GPT"""
        headers = {
            "Authorization": f"Bearer {self.iam_token}",
            "Content-Type": "application/json"
        }
        
        data = {
            "modelUri": f"gpt://{self.folder_id}/yandexgpt-lite",
            "completionOptions": {
                "stream": False,
                "temperature": 0.3,
                "maxTokens": 2000
            },
            "messages": [
                {
                    "role": "user",
                    "text": prompt
                }
            ]
        }
        
        # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ (1 —Ç–æ–∫–µ–Ω ‚âà 4 —Å–∏–º–≤–æ–ª–∞ –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ)
        input_tokens = len(prompt) // 4
        print(f"üí∞ –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ {input_tokens} –≤—Ö–æ–¥–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤", flush=True)
        
        # –†–µ–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫ Yandex GPT
        if not self.iam_token:
            print("‚ö†Ô∏è Yandex IAM —Ç–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É—é fallback")
            return {"result": {"alternatives": [{"message": {"text": "[]"}}]}}
        
        try:
            response = requests.post(self.gpt_url, headers=headers, json=data, timeout=60)
            
            if response.status_code == 200:
                result = response.json()
                # –ü–æ–¥—Å—á–µ—Ç –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
                response_text = result.get("result", {}).get("alternatives", [{}])[0].get("message", {}).get("text", "")
                output_tokens = len(response_text) // 4
                total_cost = (input_tokens * 0.0006) + (output_tokens * 0.0012)  # –ü—Ä–∏–º–µ—Ä–Ω—ã–µ —Ü–µ–Ω—ã –≤ —Ä—É–±–ª—è—Ö –∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤
                print(f"üí∞ ~{output_tokens} –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ | –°—Ç–æ–∏–º–æ—Å—Ç—å: ~{total_cost:.3f}‚ÇΩ", flush=True)
                return result
            else:
                print(f"‚ö†Ô∏è Yandex GPT –æ—à–∏–±–∫–∞ {response.status_code}: {response.text[:200]}...")
                return {"result": {"alternatives": [{"message": {"text": "[]"}}]}}
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ Yandex GPT: {e}")
            return {"result": {"alternatives": [{"message": {"text": "[]"}}]}}
    
    def _parse_gpt_response(self, response: Dict[str, Any]) -> List[LinguisticHighlight]:
        """–ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç –æ—Ç Yandex GPT"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
            text = response["result"]["alternatives"][0]["message"]["text"]
            
            # –û—á–∏—â–∞–µ–º –æ—Ç markdown —Ä–∞–∑–º–µ—Ç–∫–∏
            text = text.strip()
            if text.startswith("```"):
                text = text.split("```")[1]  # –£–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–π ```
                if text.startswith("json"):
                    text = text[4:]  # –£–±–∏—Ä–∞–µ–º "json"
                text = text.strip()
            if text.endswith("```"):
                text = text[:-3].strip()
            
            # –ü–∞—Ä—Å–∏–º JSON
            highlights_data = json.loads(text)
            
            highlights = []
            for item in highlights_data:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ö–∞–π–ª–∞–π—Ç –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –µ—Å—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
                highlight_text = item["highlight"].lower()
                context_text = item["context"].lower()
                
                # –î–ª—è —Ñ—Ä–∞–∑ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ —á–∞—Å—Ç—è–º
                words_in_context = True
                if ' ' in highlight_text:
                    for word in highlight_text.split():
                        if len(word) > 2 and word not in context_text:
                            words_in_context = False
                            break
                else:
                    # –î–ª—è –æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞
                    words_in_context = highlight_text in context_text
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ö–∞–π–ª–∞–π—Ç—ã, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
                if not words_in_context:
                    print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é —Ö–∞–π–ª–∞–π—Ç '{item['highlight']}' - –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ")
                    continue
                
                highlight = LinguisticHighlight(
                    highlight=item["highlight"],
                    context=item["context"],
                    highlight_translation=item.get("highlight_translation", item.get("context_translation", "")),
                    cefr_level="C1",  # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ - –≤—Å–µ —Å–ª–æ–≤–∞ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ
                    importance_score=85,  # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                    dictionary_meanings=[],  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ —á–µ—Ä–µ–∑ Yandex Translate
                    why_interesting="–í—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω–∞—è –ª–µ–∫—Å–∏–∫–∞ –¥–ª—è —Å—Ç–∏–ª—å–Ω–æ–π —Ä–µ—á–∏"
                )
                highlights.append(highlight)
            
            return highlights
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ GPT –æ—Ç–≤–µ—Ç–∞: {e}", flush=True)
            return []
    
    async def _add_translations(self, highlights: List[LinguisticHighlight]) -> List[LinguisticHighlight]:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–ª–æ–≤–∞—Ä–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —á–µ—Ä–µ–∑ Yandex Translate (legacy method)"""
        for highlight in highlights:
            try:
                # –ü–æ–ª—É—á–∞–µ–º —Å–ª–æ–≤–∞—Ä–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Å–ª–æ–≤–∞
                dictionary_meanings = self._get_dictionary_meanings(highlight.highlight)
                highlight.dictionary_meanings = dictionary_meanings

            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ª–æ–≤–∞—Ä–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è '{highlight.highlight}': {e}", flush=True)
                highlight.dictionary_meanings = [f"–ó–Ω–∞—á–µ–Ω–∏–µ: {highlight.highlight}"]

        return highlights
    
    def _is_primitive_word(self, word: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–ª–æ–≤–æ –ø—Ä–∏–º–∏—Ç–∏–≤–Ω—ã–º/–±–∞–∑–æ–≤—ã–º"""
        clean_word = word.strip().lower()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤ —Å–ø–∏—Å–∫–µ –ø—Ä–∏–º–∏—Ç–∏–≤–Ω—ã—Ö —Å–ª–æ–≤
        if clean_word in self.PRIMITIVE_WORDS:
            return True

        # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞ (–º–µ–Ω—å—à–µ 4 –±—É–∫–≤) - –ø—Ä–∏–º–∏—Ç–∏–≤–Ω—ã–µ
        if len(clean_word) < 4:
            return True

        return False

    # –°—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥ Free Dictionary API —É–¥–∞–ª–µ–Ω - —Ç–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ–º Yandex Dictionary API

    def _get_yandex_dict_translations(self, word: str) -> List[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Ä—É—Å—Å–∫–∏–µ –ø–µ—Ä–µ–≤–æ–¥—ã —á–µ—Ä–µ–∑ Yandex Dictionary API"""
        try:
            # –û—á–∏—â–∞–µ–º —Å–ª–æ–≤–æ
            clean_word = re.sub(r'[^a-zA-Z-]', '', word.strip().lower())
            if not clean_word or self._is_primitive_word(clean_word):
                return []

            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
            params = {
                'key': self.dict_api_key,
                'lang': 'en-ru',
                'text': clean_word
            }

            response = requests.get(self.dict_url, params=params, timeout=10)

            if response.status_code == 200:
                data = response.json()
                translations = []

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–µ—Ä–µ–≤–æ–¥—ã –∏–∑ –æ—Ç–≤–µ—Ç–∞
                for entry in data.get('def', [])[:3]:  # –ü–µ—Ä–≤—ã–µ 3 —Å–ª–æ–≤–∞—Ä–Ω—ã—Ö —Å—Ç–∞—Ç—å–∏
                    for translation in entry.get('tr', [])[:3]:  # –ü–µ—Ä–≤—ã–µ 3 –ø–µ—Ä–µ–≤–æ–¥–∞
                        trans_text = translation.get('text', '')
                        if trans_text and trans_text not in translations:
                            translations.append(trans_text)

                return translations[:5]  # –ú–∞–∫—Å–∏–º—É–º 5 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤
            else:
                print(f"‚ö†Ô∏è Yandex Dict API error: {response.status_code}", flush=True)
                return []

        except Exception as e:
            print(f"‚ö†Ô∏è Dictionary API error: {e}", flush=True)
            return []

    def _get_dictionary_meanings(self, word: str) -> List[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ä—É—Å—Å–∫–∏–µ –ø–µ—Ä–µ–≤–æ–¥—ã —Å–ª–æ–≤–∞ —á–µ—Ä–µ–∑ Yandex Dictionary API

        –î–ª—è —Ñ—Ä–∞–∑: —Ä–∞–∑–±–∏–≤–∞–µ—Ç –Ω–∞ —Å–ª–æ–≤–∞, —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –ø—Ä–∏–º–∏—Ç–∏–≤–Ω—ã–µ, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–µ–≤–æ–¥—ã —Å–ª–æ–∂–Ω—ã—Ö —Å–ª–æ–≤
        –î–ª—è –æ–¥–∏–Ω–æ—á–Ω—ã—Ö —Å–ª–æ–≤: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –ø–µ—Ä–µ–≤–æ–¥—ã
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ API –∫–ª—é—á–∞
            if not self.dict_api_key:
                print("‚ö†Ô∏è YANDEX_DICT_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env", flush=True)
                return []

            # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
            clean_text = re.sub(r'[^a-zA-Z\s-]', '', word.strip().lower())
            if not clean_text:
                return []

            # –ï—Å–ª–∏ —Ñ—Ä–∞–∑–∞ (–Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤) - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ
            if ' ' in clean_text:
                words = clean_text.split()
                all_translations = []

                for w in words:
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–º–∏—Ç–∏–≤–Ω—ã–µ —Å–ª–æ–≤–∞
                    if self._is_primitive_word(w):
                        continue

                    # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–µ–≤–æ–¥—ã –¥–ª—è —Å–ª–æ–∂–Ω–æ–≥–æ —Å–ª–æ–≤–∞
                    translations = self._get_yandex_dict_translations(w)
                    if translations:
                        all_translations.extend(translations[:2])  # –ú–∞–∫—Å–∏–º—É–º 2 –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–∞ —Å–ª–æ–≤–æ

                return all_translations[:5]  # –í—Å–µ–≥–æ –º–∞–∫—Å–∏–º—É–º 5 –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –¥–ª—è —Ñ—Ä–∞–∑—ã
            else:
                # –û–¥–∏–Ω–æ—á–Ω–æ–µ —Å–ª–æ–≤–æ
                return self._get_yandex_dict_translations(clean_text)[:5]  # –ú–∞–∫—Å–∏–º—É–º 5 –ø–µ—Ä–µ–≤–æ–¥–æ–≤

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–µ—Ä–µ–≤–æ–¥–æ–≤: {e}", flush=True)
            return []

    def get_dictionary_meanings(self, highlight_text: str) -> List[str]:
        """–ü—É–±–ª–∏—á–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ª–æ–≤–∞—Ä–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (–¥–ª—è –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã)"""
        return self._get_dictionary_meanings(highlight_text)

    def _translate_definition_sync(self, definition: str) -> str:
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç –∞–Ω–≥–ª–∏–π—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —á–µ—Ä–µ–∑ Yandex Translate (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)"""
        try:
            print(f"üîÑ [TRANSLATE] –ü–µ—Ä–µ–≤–æ–¥–∏–º: '{definition}'", flush=True)
            print(f"üîÑ [TRANSLATE] IAM token: {self.iam_token[:20]}...", flush=True)
            print(f"üîÑ [TRANSLATE] Folder ID: {self.folder_id}", flush=True)

            headers = {
                "Authorization": f"Bearer {self.iam_token}",
                "Content-Type": "application/json"
            }

            data = {
                "folderId": self.folder_id,
                "texts": [definition],
                "sourceLanguageCode": "en",
                "targetLanguageCode": "ru"
            }

            response = requests.post(
                "https://translate.api.cloud.yandex.net/translate/v2/translate",
                headers=headers,
                json=data,
                timeout=10
            )

            print(f"üîÑ [TRANSLATE] Status: {response.status_code}", flush=True)

            if response.status_code == 200:
                result = response.json()
                print(f"üîÑ [TRANSLATE] Response: {result}", flush=True)
                translation = result["translations"][0]["text"]
                print(f"‚úÖ [TRANSLATE] –ü–æ–ª—É—á–µ–Ω –ø–µ—Ä–µ–≤–æ–¥: '{translation}'", flush=True)
                return translation
            else:
                print(f"‚ùå [TRANSLATE] –û—à–∏–±–∫–∞: {response.status_code} - {response.text}", flush=True)
                return definition  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –µ—Å–ª–∏ –ø–µ—Ä–µ–≤–æ–¥ –Ω–µ —É–¥–∞–ª—Å—è

        except Exception as e:
            print(f"‚ùå [TRANSLATE] Exception: {e}", flush=True)
            import traceback
            traceback.print_exc()
            return definition  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª

    async def _translate_definition(self, definition: str) -> str:
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç –∞–Ω–≥–ª–∏–π—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —á–µ—Ä–µ–∑ Yandex Translate"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–π Yandex Translate API
            headers = {
                "Authorization": f"Bearer {self.iam_token}",
                "Content-Type": "application/json"
            }
            
            data = {
                "folderId": self.folder_id,
                "texts": [definition],
                "sourceLanguageCode": "en",
                "targetLanguageCode": "ru"
            }
            
            response = requests.post(
                "https://translate.api.cloud.yandex.net/translate/v2/translate",
                headers=headers, 
                json=data, 
                timeout=10
            )
            
            if response.status_code == 200:
                result = response.json()
                translation = result["translations"][0]["text"]
                return translation
            else:
                return definition  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –µ—Å–ª–∏ –ø–µ—Ä–µ–≤–æ–¥ –Ω–µ —É–¥–∞–ª—Å—è
                
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è: {e}", flush=True)
            return definition  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª

    async def _translate_text(self, text: str) -> str:
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ Yandex Translate"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –≤ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ–±–µ—Ä—Ç–∫–µ
            translation = self._translate_definition_sync(text)
            return translation
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞: {e}", flush=True)
            return text  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –ø—Ä–∏ –æ—à–∏–±–∫–µ
    
    def _fallback_analysis(self, text: str) -> List[LinguisticHighlight]:
        """Fallback –∞–Ω–∞–ª–∏–∑ –µ—Å–ª–∏ GPT –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"""
        print("üîÑ –ò—Å–ø–æ–ª—å–∑—É—é fallback –∞–Ω–∞–ª–∏–∑...", flush=True)
        
        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        words = text.split()
        interesting_words = [w for w in words if len(w) > 6 and w.isalpha()][:5]
        
        highlights = []
        for word in interesting_words:
            highlight = LinguisticHighlight(
                highlight=word.lower(),
                context=f"Found in: ...{word}...",
                highlight_translation=f"–ù–∞–π–¥–µ–Ω–æ –≤: ...{word}...",
                cefr_level="B2",
                importance_score=70,
                dictionary_meanings=[f"–ó–Ω–∞—á–µ–Ω–∏–µ —Å–ª–æ–≤–∞ {word}"],
                why_interesting=f"–î–ª–∏–Ω–Ω–æ–µ —Å–ª–æ–≤–æ, –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–µ"
            )
            highlights.append(highlight)

        return highlights

    # –ü—É–±–ª–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π
    async def request_gpt(self, prompt: str) -> str:
        """–ü—É–±–ª–∏—á–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –∫ GPT (–¥–ª—è –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã)"""
        result = await self._request_yandex_gpt(prompt)
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
        return result.get("result", {}).get("alternatives", [{}])[0].get("message", {}).get("text", "")

    async def translate_text(self, text: str, target_lang: str = "ru") -> str:
        """–ü—É–±–ª–∏—á–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ (–¥–ª—è –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã)"""
        return await self._translate_text(text)

def test_yandex_ai_client():
    """–¢–µ—Å—Ç –∫–ª–∏–µ–Ω—Ç–∞ Yandex AI"""
    import asyncio
    
    async def run_test():
        print("üß™ –¢–ï–°–¢ YANDEX AI CLIENT")
        print("=" * 50)
        
        client = YandexAIClient()
        
        test_text = """
        Machine learning algorithms analyze complex patterns in massive datasets. 
        These sophisticated methods revolutionize artificial intelligence research.
        Scientists develop innovative approaches to solve computational problems.
        """
        
        highlights = await client.analyze_linguistic_highlights(test_text.strip())
        
        print(f"\nüìö –ù–∞–π–¥–µ–Ω–æ {len(highlights)} —Ö–∞–π–ª–∞–π—Ç–æ–≤:")
        for i, h in enumerate(highlights):
            print(f"\n{i+1}. {h.highlight} ({h.cefr_level})")
            print(f"   üìù –ö–æ–Ω—Ç–µ–∫—Å—Ç: {h.context}")
            print(f"   üá∑üá∫ –ü–µ—Ä–µ–≤–æ–¥: {h.highlight_translation}")
            print(f"   üí° –ü–æ—á–µ–º—É –∏–Ω—Ç–µ—Ä–µ—Å–µ–Ω: {h.why_interesting}")
            print(f"   üìä –í–∞–∂–Ω–æ—Å—Ç—å: {h.importance_score}/100")
        
        print("\n‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω!")
    
    asyncio.run(run_test())

if __name__ == "__main__":
    test_yandex_ai_client()