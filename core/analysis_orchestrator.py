#!/usr/bin/env python3
"""
ðŸŽ­ ANALYSIS ORCHESTRATOR

ÐžÑ€ÐºÐµÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ‚ÐµÐºÑÑ‚Ð° Ñ‡ÐµÑ€ÐµÐ· Yandex AI Studio Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð².
ÐšÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð¸Ñ€ÑƒÐµÑ‚ Ð²Ñ‹Ð·Ð¾Ð²Ñ‹ Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð², ÑÐ¾Ð±Ð¸Ñ€Ð°ÐµÑ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹, ÑƒÐ±Ð¸Ñ€Ð°ÐµÑ‚ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ñ‹.

@version 2.0.0 (Agent Refactoring)
@author Wordoorio Team
"""

import asyncio
import json
import logging
from typing import List, Dict, Any
from contracts.analysis_contracts import (
    Highlight,
    AnalysisResult,
    AnalysisRequest,
    AgentResponse,
    create_success_result,
    create_error_result
)
from core.yandex_ai_client import YandexAIClient
from utils.lemmatizer import lemmatize

# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
logger = logging.getLogger(__name__)


class AnalysisOrchestrator:
    """
    ÐšÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ð¾Ñ€ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ‚ÐµÐºÑÑ‚Ð°

    Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ Yandex AI Studio Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð²:
    - Agent #1 (fvt3bjtulehmg0v8tss3): ÐÐ½Ð°Ð»Ð¸Ð· ÑÐ»Ð¾Ð²
    - Agent #2 (fvt6j0ev2cgf1q2itfr6): ÐÐ½Ð°Ð»Ð¸Ð· Ñ„Ñ€Ð°Ð·
    """

    # ID Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð² Ð² Yandex AI Studio
    AGENT_WORDS_ID = "fvt3bjtulehmg0v8tss3"      # ÐÐ³ÐµÐ½Ñ‚ #1: ÐÐ½Ð°Ð»Ð¸Ð· ÑÐ»Ð¾Ð²
    AGENT_PHRASES_ID = "fvt6j0ev2cgf1q2itfr6"    # ÐÐ³ÐµÐ½Ñ‚ #2: ÐÐ½Ð°Ð»Ð¸Ð· Ñ„Ñ€Ð°Ð·

    def __init__(self, ai_client: YandexAIClient):
        """
        Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¾Ñ€ÐºÐµÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°

        Args:
            ai_client: ÐšÐ»Ð¸ÐµÐ½Ñ‚ Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ Yandex AI Studio
        """
        self.ai_client = ai_client

    async def analyze_text(self, request: AnalysisRequest) -> AnalysisResult:
        """
        ÐÐ½Ð°Ð»Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð° Ñ‡ÐµÑ€ÐµÐ· Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð² Yandex AI Studio

        ÐÐ»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼:
        1. Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
        2. ÐŸÐ°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð²Ñ‹Ð·Ð¾Ð² Agent #1 (ÑÐ»Ð¾Ð²Ð°) Ð¸ Agent #2 (Ñ„Ñ€Ð°Ð·Ñ‹)
        3. Ð¡Ð±Ð¾Ñ€ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð² Ð¾Ñ‚ Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð²
        4. ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ AgentResponse â†’ Highlight
        5. Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ ÑÐ»Ð¾Ð²Ð°Ñ€Ð½Ñ‹Ñ… Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹
        6. Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð²
        7. Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‚ AnalysisResult

        Args:
            request: Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð½Ð° Ð°Ð½Ð°Ð»Ð¸Ð·

        Returns:
            AnalysisResult: Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ Ñ…Ð°Ð¹Ð»Ð°Ð¹Ñ‚Ð°Ð¼Ð¸
        """
        import time
        start_time = time.time()
        logger.info(f"[ORCHESTRATOR] ÐÐ°Ñ‡Ð°Ð»Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ‚ÐµÐºÑÑ‚Ð° ({len(request.text)} ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²)")

        # Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
        error = request.validate()
        if error:
            return create_error_result(error)

        try:
            # ÐŸÐ°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð²Ñ‹Ð·Ð¾Ð² Ð´Ð²ÑƒÑ… Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð²
            agents_start = time.time()
            words_task = self._call_words_agent(request.text)
            phrases_task = self._call_phrases_agent(request.text)

            # Ð–Ð´ÐµÐ¼ Ð¾Ð±Ð° Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°
            words_responses, phrases_responses = await asyncio.gather(
                words_task,
                phrases_task,
                return_exceptions=True
            )
            agents_time = time.time() - agents_start
            logger.info(f"Ð’Ñ€ÐµÐ¼Ñ Ð²Ñ‹Ð·Ð¾Ð²Ð° Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð²: {agents_time:.2f}s")

            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¾ÑˆÐ¸Ð±ÐºÐ¸
            if isinstance(words_responses, Exception):
                logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Agent #1 (words): {words_responses}")
                words_responses = []

            if isinstance(phrases_responses, Exception):
                logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Agent #2 (phrases): {phrases_responses}")
                phrases_responses = []

            # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ AgentResponse â†’ Highlight (Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾!)
            processing_start = time.time()

            # Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð²ÑÐµ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ñ Ð´Ð»Ñ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ
            tasks = []
            for agent_response in words_responses:
                for highlight_dict in agent_response.highlights:
                    tasks.append(self._dict_to_highlight(highlight_dict, request.text))

            for agent_response in phrases_responses:
                for highlight_dict in agent_response.highlights:
                    tasks.append(self._dict_to_highlight(highlight_dict, request.text))

            # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð²ÑÐµ Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾
            logger.info(f"Ð—Ð°Ð¿ÑƒÑÐº {len(tasks)} Ð·Ð°Ð´Ð°Ñ‡ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾")
            highlights_results = await asyncio.gather(*tasks, return_exceptions=True)

            # Ð¤Ð¸Ð»ÑŒÑ‚Ñ€ÑƒÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
            highlights = []
            for result in highlights_results:
                if isinstance(result, Exception):
                    logger.warning(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ highlight: {result}")
                elif result:
                    highlights.append(result)

            processing_time = time.time() - processing_start
            logger.info(f"Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ñ…Ð°Ð¹Ð»Ð°Ð¹Ñ‚Ð¾Ð² (Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾): {processing_time:.2f}s")

            # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ñ‹
            highlights = self._remove_duplicates(highlights)

            # ÐŸÐ¾Ð´ÑÑ‡ÐµÑ‚ ÑÐ»Ð¾Ð²
            word_count = len(request.text.split())

            total_time = time.time() - start_time
            logger.info(f"ÐžÐ‘Ð©Ð•Ð• Ð’Ð Ð•ÐœÐ¯: {total_time:.2f}s")
            logger.info(f"[ORCHESTRATOR] ÐÐ½Ð°Ð»Ð¸Ð· Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½: {len(highlights)} Ñ…Ð°Ð¹Ð»Ð°Ð¹Ñ‚Ð¾Ð²")

            return create_success_result(
                highlights=highlights,
                total_words=word_count,
                performance={
                    'words_agent_results': len(words_responses) if not isinstance(words_responses, Exception) else 0,
                    'phrases_agent_results': len(phrases_responses) if not isinstance(phrases_responses, Exception) else 0,
                    'total_highlights': len(highlights),
                    'agents_time': f"{agents_time:.2f}s",
                    'processing_time': f"{processing_time:.2f}s",
                    'total_time': f"{total_time:.2f}s"
                }
            )

        except Exception as e:
            logger.error(f"[ORCHESTRATOR] ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°: {e}", exc_info=True)
            return create_error_result(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°: {str(e)}")

    async def _call_words_agent(self, text: str) -> List[AgentResponse]:
        """
        Ð’Ñ‹Ð·Ð¾Ð² Agent #1 (Ð°Ð½Ð°Ð»Ð¸Ð· ÑÐ»Ð¾Ð²)

        Args:
            text: Ð¢ÐµÐºÑÑ‚ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°

        Returns:
            List[AgentResponse]: Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ñ… ÑÐ»Ð¾Ð²
        """
        logger.info("[AGENT #1] ÐÐ½Ð°Ð»Ð¸Ð· ÑÐ»Ð¾Ð²...")

        try:
            # Ð’Ñ‹Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð°Ð³ÐµÐ½Ñ‚Ð° Ñ‡ÐµÑ€ÐµÐ· AI Studio (Ð¿ÐµÑ€ÐµÐ´Ð°ÐµÐ¼ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ñ‚ÐµÐºÑÑ‚)
            response = await self.ai_client.call_agent(self.AGENT_WORDS_ID, text)

            # ÐÐ³ÐµÐ½Ñ‚ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¾Ð´Ð¸Ð½ AgentResponse, Ð½Ð¾ Ð¼Ñ‹ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ ÑÐ¿Ð¸ÑÐ¾Ðº Ð´Ð»Ñ ÐµÐ´Ð¸Ð½Ð¾Ð¾Ð±Ñ€Ð°Ð·Ð¸Ñ
            return [response]

        except Exception as e:
            logger.error(f"[AGENT #1] ÐžÑˆÐ¸Ð±ÐºÐ°: {e}", exc_info=True)
            raise

    async def _call_phrases_agent(self, text: str) -> List[AgentResponse]:
        """
        Ð’Ñ‹Ð·Ð¾Ð² Agent #2 (Ð°Ð½Ð°Ð»Ð¸Ð· Ñ„Ñ€Ð°Ð·)

        Args:
            text: Ð¢ÐµÐºÑÑ‚ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°

        Returns:
            List[AgentResponse]: Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ñ… Ñ„Ñ€Ð°Ð·
        """
        logger.info("[AGENT #2] ÐÐ½Ð°Ð»Ð¸Ð· Ñ„Ñ€Ð°Ð·...")

        try:
            # Ð’Ñ‹Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð°Ð³ÐµÐ½Ñ‚Ð° Ñ‡ÐµÑ€ÐµÐ· AI Studio (Ð¿ÐµÑ€ÐµÐ´Ð°ÐµÐ¼ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ñ‚ÐµÐºÑÑ‚)
            response = await self.ai_client.call_agent(self.AGENT_PHRASES_ID, text)

            # ÐÐ³ÐµÐ½Ñ‚ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¾Ð´Ð¸Ð½ AgentResponse
            return [response]

        except Exception as e:
            logger.error(f"[AGENT #2] ÐžÑˆÐ¸Ð±ÐºÐ°: {e}", exc_info=True)
            raise

    async def _dict_to_highlight(self, highlight_dict: Dict[str, Any], original_text: str) -> Highlight:
        """
        ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ ÑÐ»Ð¾Ð²Ð°Ñ€Ñ Ð¸Ð· AgentResponse â†’ Highlight

        Args:
            highlight_dict: Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ñ…Ð°Ð¹Ð»Ð°Ð¹Ñ‚Ð° Ð¾Ñ‚ Ð°Ð³ÐµÐ½Ñ‚Ð°
            original_text: ÐžÑ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ (Ð½Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ, Ñ‚.Ðº. ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ ÑƒÐ¶Ðµ Ð² highlight_dict)

        Returns:
            Highlight: Ð¥Ð°Ð¹Ð»Ð°Ð¹Ñ‚ Ð´Ð»Ñ Ñ„Ñ€Ð¾Ð½Ñ‚ÐµÐ½Ð´Ð°
        """
        try:
            import time
            word = highlight_dict.get('highlight', '')

            # Ð›ÐµÐ¼Ð¼Ð°Ñ‚Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ»Ð¾Ð²Ð¾ Ð´Ð»Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ð² ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ
            lemma_start = time.time()
            word_lemma = lemmatize(word)
            lemma_time = time.time() - lemma_start

            # Yandex Dictionary API Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ Ð¢ÐžÐ›Ð¬ÐšÐž Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð°, ÐÐ• Ñ„Ñ€Ð°Ð·Ñ‹
            word_count = len(word_lemma.split())

            if word_count > 1:
                # Ð¤Ñ€Ð°Ð·Ð° (2+ ÑÐ»Ð¾Ð²) - ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ð½Ðµ Ð½ÑƒÐ¶ÐµÐ½ (Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¼ÑƒÑÐ¾Ñ€)
                dictionary_meanings = []
                dict_time = 0
                print(f"ðŸ”„ {word} â†’ {word_lemma} [Ñ„Ñ€Ð°Ð·Ð° Ð¸Ð· {word_count} ÑÐ»Ð¾Ð², ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ð¿Ñ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½]", flush=True)
            else:
                # ÐžÑ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ðµ ÑÐ»Ð¾Ð²Ð¾ (1 ÑÐ»Ð¾Ð²Ð¾) - Ð·Ð°Ð¿Ñ€Ð°ÑˆÐ¸Ð²Ð°ÐµÐ¼ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ
                dict_start = time.time()

                # Ð¡Ð¢Ð ÐÐ¢Ð•Ð“Ð˜Ð¯: Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð», Ð¿Ð¾Ñ‚Ð¾Ð¼ Ð»ÐµÐ¼Ð¼Ð°
                # 1. ÐŸÑ€Ð¾Ð±ÑƒÐµÐ¼ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð» (implied)
                dictionary_meanings = await self.ai_client.get_dictionary_meanings(word)
                dict_query = word

                # 2. Ð•ÑÐ»Ð¸ Ð¿ÑƒÑÑ‚Ð¾ Ð¸ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð» != Ð»ÐµÐ¼Ð¼Ð°, Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ Ð»ÐµÐ¼Ð¼Ñƒ (imply)
                if not dictionary_meanings and word.lower() != word_lemma.lower():
                    dictionary_meanings = await self.ai_client.get_dictionary_meanings(word_lemma)
                    dict_query = f"{word}â†’{word_lemma}"

                dict_time = time.time() - dict_start
                print(f"ðŸ”„ {word} â†’ {word_lemma} [Ð»ÐµÐ¼Ð¼Ð°: {lemma_time*1000:.0f}ms, ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ '{dict_query}': {dict_time*1000:.0f}ms]", flush=True)

            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´ Ð¾Ñ‚ Ð°Ð³ÐµÐ½Ñ‚Ð°
            main_translation = highlight_dict.get('highlight_translation', '').lower().strip()

            # Ð˜ÑÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´ Ð¸Ð· Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹ (ÑƒÐ±Ð¸Ñ€Ð°ÐµÐ¼ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚)
            if main_translation and dictionary_meanings:
                # ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼ ÑÑ‚Ñ€Ð¾ÐºÐ¸: Ð½Ð¸Ð¶Ð½Ð¸Ð¹ Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€, Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹ (Ð·Ð°Ð¼ÐµÐ½ÑÐµÐ¼ Ð»ÑŽÐ±Ñ‹Ðµ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹ Ð½Ð° Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ðµ)
                import re
                def normalize(s):
                    # Ð—Ð°Ð¼ÐµÐ½ÑÐµÐ¼ Ð»ÑŽÐ±Ñ‹Ðµ Ð¿Ñ€Ð¾Ð±ÐµÐ»ÑŒÐ½Ñ‹Ðµ ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ‹ Ð½Ð° Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð±ÐµÐ»
                    normalized = re.sub(r'\s+', ' ', s.strip().lower())
                    return normalized

                main_normalized = normalize(main_translation)

                filtered = []
                duplicates_removed = 0
                for meaning in dictionary_meanings:
                    meaning_normalized = normalize(meaning)

                    # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ñ‚Ð¾Ñ‡Ð½Ñ‹Ðµ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ: "ÑƒÑÐ¸Ð»Ð¸Ð²Ð°Ñ‚ÑŒ" == "ÑƒÑÐ¸Ð»Ð¸Ð²Ð°Ñ‚ÑŒ"
                    if meaning_normalized == main_normalized:
                        duplicates_removed += 1
                        continue

                    filtered.append(meaning)

                dictionary_meanings = filtered
                if duplicates_removed > 0:
                    print(f"   ðŸ—‘ï¸ Ð£Ð±Ñ€Ð°Ð½Ð¾ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð²: {duplicates_removed}", flush=True)
                print(f"   ðŸ“– Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹: {len(dictionary_meanings)}", flush=True)

            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Highlight Ð¸Ð· Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð°Ð³ÐµÐ½Ñ‚Ð°
            highlight = Highlight(
                highlight=word,  # ÐžÑ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ ÑÐ»Ð¾Ð²Ð¾ - Ñ‚Ð¾ Ñ‡Ñ‚Ð¾ Ð²Ð¸Ð´Ð¸Ñ‚ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ
                context=highlight_dict.get('context', ''),  # ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ñ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ñ„Ð¾Ñ€Ð¼Ð¾Ð¹
                highlight_translation=highlight_dict.get('highlight_translation', ''),
                lemma=word_lemma,  # Ð›ÐµÐ¼Ð¼Ð°Ñ‚Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ Ñ„Ð¾Ñ€Ð¼Ð° Ð´Ð»Ñ Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ð² Ð‘Ð”
                dictionary_meanings=dictionary_meanings
            )

            return highlight

        except Exception as e:
            print(f"âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ñ highlight dict: {e}", flush=True)
            return None

    def _extract_context(self, word: str, text: str) -> str:
        """
        Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° (Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ) Ð´Ð»Ñ ÑÐ»Ð¾Ð²Ð° Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð°

        Args:
            word: Ð¡Ð»Ð¾Ð²Ð¾/Ñ„Ñ€Ð°Ð·Ð° Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ°
            text: Ð˜ÑÑ…Ð¾Ð´Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚

        Returns:
            str: ÐŸÑ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ, ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‰ÐµÐµ ÑÐ»Ð¾Ð²Ð¾
        """
        # Ð Ð°Ð·Ð±Ð¸Ð²Ð°ÐµÐ¼ Ñ‚ÐµÐºÑÑ‚ Ð½Ð° Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ
        sentences = text.replace('!', '.').replace('?', '.').split('.')

        # Ð˜Ñ‰ÐµÐ¼ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ, ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‰ÐµÐµ ÑÐ»Ð¾Ð²Ð¾
        word_lower = word.lower()
        for sentence in sentences:
            if word_lower in sentence.lower():
                return sentence.strip()

        # Ð•ÑÐ»Ð¸ Ð½Ðµ Ð½Ð°ÑˆÐ»Ð¸ - Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð½Ð°Ñ‡Ð°Ð»Ð¾ Ñ‚ÐµÐºÑÑ‚Ð°
        return text[:200].strip()

    def _remove_duplicates(self, highlights: List[Highlight]) -> List[Highlight]:
        """
        Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð² Ð¸Ð· ÑÐ¿Ð¸ÑÐºÐ° Ñ…Ð°Ð¹Ð»Ð°Ð¹Ñ‚Ð¾Ð² Ð¿Ð¾ Ð»ÐµÐ¼Ð¼Ð°Ð¼

        Args:
            highlights: Ð¡Ð¿Ð¸ÑÐ¾Ðº Ñ…Ð°Ð¹Ð»Ð°Ð¹Ñ‚Ð¾Ð²

        Returns:
            List[Highlight]: Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð±ÐµÐ· Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð²
        """
        seen = set()
        unique_highlights = []

        for highlight in highlights:
            # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð³Ð¾Ñ‚Ð¾Ð²ÑƒÑŽ Ð»ÐµÐ¼Ð¼Ñƒ Ð¸Ð· Highlight (ÑƒÐ¶Ðµ Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð° Ñ€Ð°Ð½ÐµÐµ)
            # amplify/amplifying/amplified = Ð¾Ð´Ð½Ð° Ð»ÐµÐ¼Ð¼Ð° "amplify"
            lemma = highlight.lemma.lower() if highlight.lemma else highlight.highlight.lower()

            if lemma not in seen:
                seen.add(lemma)
                unique_highlights.append(highlight)

        removed_count = len(highlights) - len(unique_highlights)
        if removed_count > 0:
            print(f"ðŸ”„ Ð£Ð´Ð°Ð»ÐµÐ½Ð¾ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð²: {removed_count}", flush=True)

        return unique_highlights
